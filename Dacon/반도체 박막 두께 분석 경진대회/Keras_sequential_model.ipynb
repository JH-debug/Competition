{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Try_4.ipynb","provenance":[{"file_id":"16_BXB6ecCj0JyFoeAm6nTxtDrk-H1-VD","timestamp":1579748695595}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"n5lx_5OZwgzj","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1580309691015,"user_tz":-540,"elapsed":63999,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}},"outputId":"9bcb4e66-a35c-41f4-a78a-7bd288e29b57"},"source":["import pandas as pd\n","import numpy as np\n","from scipy.stats import norm\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","train = pd.read_csv(work_dir + \"train.csv\")\n","test = pd.read_csv(work_dir + \"test.csv\")\n","\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(810000, 230)\n","(10000, 227)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jyD77uXBwgzr"},"source":["fea_train = train.iloc[:,4:]  # Train 데이터의 feature\n","tar_train = train.iloc[:,0:4] # Train 데이터의 target\n","\n","tar_train_n4 = train[['layer_1','layer_3']] # 질화규소 층\n","tar_train_o2 = train[['layer_2','layer_4']] # 산화규소 층"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epRzZSdEwgzv"},"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense,Dropout\n","from keras.callbacks import ModelCheckpoint\n","import keras.optimizers\n","\n","MODEL_SAVE_FOLDER_PATH = work_dir \n","if not os.path.exists(MODEL_SAVE_FOLDER_PATH): \n","    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","    \n","model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}_{acc:.5f}.hdf5' \n","cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='acc', verbose=1, save_best_only=True)\n","\n","model = Sequential()\n","model.add(Dense(units=fea_train.shape[1], activation='relu', input_dim=fea_train.shape[1], kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(units=fea_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n","\n","model.add(Dense(units=2, activation='linear', kernel_initializer='he_normal'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"wi63cjevwgzy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1580321685974,"user_tz":-540,"elapsed":4576321,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}},"outputId":"52b6f69c-d02c-426a-9972-035c2f3e0c08"},"source":["# 질화규소 층\n","\n","model.compile(loss='mae', optimizer='adam', metrics=['acc']) \n","model.fit(fea_train, tar_train_n4 , epochs=1000, batch_size=1000,callbacks=[cb_checkpoint], validation_split = 0.05)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 769500 samples, validate on 40500 samples\n","Epoch 1/1000\n","769500/769500 [==============================] - 16s 21us/step - loss: 22.4917 - acc: 0.8721 - val_loss: 29.3327 - val_acc: 0.8586\n","\n","Epoch 00001: acc did not improve from 0.97795\n","Epoch 2/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 8.3708 - acc: 0.9542 - val_loss: 23.3930 - val_acc: 0.9001\n","\n","Epoch 00002: acc did not improve from 0.97795\n","Epoch 3/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 6.1236 - acc: 0.9658 - val_loss: 21.8328 - val_acc: 0.8842\n","\n","Epoch 00003: acc did not improve from 0.97795\n","Epoch 4/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 5.0684 - acc: 0.9709 - val_loss: 18.5372 - val_acc: 0.9081\n","\n","Epoch 00004: acc did not improve from 0.97795\n","Epoch 5/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 4.4867 - acc: 0.9736 - val_loss: 17.2074 - val_acc: 0.9026\n","\n","Epoch 00005: acc did not improve from 0.97795\n","Epoch 6/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 4.0357 - acc: 0.9755 - val_loss: 17.2622 - val_acc: 0.9084\n","\n","Epoch 00006: acc did not improve from 0.97795\n","Epoch 7/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.7007 - acc: 0.9769 - val_loss: 18.2827 - val_acc: 0.9116\n","\n","Epoch 00007: acc did not improve from 0.97795\n","Epoch 8/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.4800 - acc: 0.9778 - val_loss: 15.5795 - val_acc: 0.9160\n","\n","Epoch 00008: acc did not improve from 0.97795\n","Epoch 9/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.2656 - acc: 0.9786 - val_loss: 15.3571 - val_acc: 0.9179\n","\n","Epoch 00009: acc improved from 0.97795 to 0.97865, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/09_0.97865.hdf5\n","Epoch 10/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.1073 - acc: 0.9792 - val_loss: 14.8876 - val_acc: 0.9155\n","\n","Epoch 00010: acc improved from 0.97865 to 0.97920, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/10_0.97920.hdf5\n","Epoch 11/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.9693 - acc: 0.9796 - val_loss: 15.0965 - val_acc: 0.9150\n","\n","Epoch 00011: acc improved from 0.97920 to 0.97959, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/11_0.97959.hdf5\n","Epoch 12/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.8793 - acc: 0.9799 - val_loss: 15.8877 - val_acc: 0.9095\n","\n","Epoch 00012: acc improved from 0.97959 to 0.97993, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/12_0.97993.hdf5\n","Epoch 13/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.7581 - acc: 0.9804 - val_loss: 14.7502 - val_acc: 0.9276\n","\n","Epoch 00013: acc improved from 0.97993 to 0.98043, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/13_0.98043.hdf5\n","Epoch 14/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.6726 - acc: 0.9807 - val_loss: 13.8059 - val_acc: 0.9297\n","\n","Epoch 00014: acc improved from 0.98043 to 0.98071, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/14_0.98071.hdf5\n","Epoch 15/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.6171 - acc: 0.9809 - val_loss: 15.4731 - val_acc: 0.9178\n","\n","Epoch 00015: acc improved from 0.98071 to 0.98086, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/15_0.98086.hdf5\n","Epoch 16/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.5443 - acc: 0.9811 - val_loss: 12.8042 - val_acc: 0.9223\n","\n","Epoch 00016: acc improved from 0.98086 to 0.98107, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/16_0.98107.hdf5\n","Epoch 17/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.4537 - acc: 0.9814 - val_loss: 13.6345 - val_acc: 0.9306\n","\n","Epoch 00017: acc improved from 0.98107 to 0.98136, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/17_0.98136.hdf5\n","Epoch 18/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.4013 - acc: 0.9816 - val_loss: 12.9912 - val_acc: 0.9323\n","\n","Epoch 00018: acc improved from 0.98136 to 0.98160, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/18_0.98160.hdf5\n","Epoch 19/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.3794 - acc: 0.9816 - val_loss: 12.4539 - val_acc: 0.9295\n","\n","Epoch 00019: acc did not improve from 0.98160\n","Epoch 20/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.3152 - acc: 0.9817 - val_loss: 12.4730 - val_acc: 0.9302\n","\n","Epoch 00020: acc improved from 0.98160 to 0.98170, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/20_0.98170.hdf5\n","Epoch 21/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2744 - acc: 0.9818 - val_loss: 13.0802 - val_acc: 0.9188\n","\n","Epoch 00021: acc improved from 0.98170 to 0.98182, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/21_0.98182.hdf5\n","Epoch 22/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2404 - acc: 0.9820 - val_loss: 14.3237 - val_acc: 0.9160\n","\n","Epoch 00022: acc improved from 0.98182 to 0.98201, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/22_0.98201.hdf5\n","Epoch 23/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2023 - acc: 0.9820 - val_loss: 13.0047 - val_acc: 0.9322\n","\n","Epoch 00023: acc did not improve from 0.98201\n","Epoch 24/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1748 - acc: 0.9822 - val_loss: 13.0333 - val_acc: 0.9221\n","\n","Epoch 00024: acc improved from 0.98201 to 0.98223, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/24_0.98223.hdf5\n","Epoch 25/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1513 - acc: 0.9820 - val_loss: 13.4771 - val_acc: 0.9234\n","\n","Epoch 00025: acc did not improve from 0.98223\n","Epoch 26/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0864 - acc: 0.9821 - val_loss: 12.0552 - val_acc: 0.9329\n","\n","Epoch 00026: acc did not improve from 0.98223\n","Epoch 27/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 2.1106 - acc: 0.9821 - val_loss: 11.8910 - val_acc: 0.9372\n","\n","Epoch 00027: acc did not improve from 0.98223\n","Epoch 28/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0587 - acc: 0.9823 - val_loss: 12.4944 - val_acc: 0.9290\n","\n","Epoch 00028: acc improved from 0.98223 to 0.98228, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/28_0.98228.hdf5\n","Epoch 29/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0327 - acc: 0.9823 - val_loss: 12.2281 - val_acc: 0.9323\n","\n","Epoch 00029: acc improved from 0.98228 to 0.98232, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/29_0.98232.hdf5\n","Epoch 30/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0272 - acc: 0.9824 - val_loss: 12.9313 - val_acc: 0.9278\n","\n","Epoch 00030: acc improved from 0.98232 to 0.98238, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/30_0.98238.hdf5\n","Epoch 31/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9667 - acc: 0.9824 - val_loss: 12.0740 - val_acc: 0.9294\n","\n","Epoch 00031: acc improved from 0.98238 to 0.98243, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/31_0.98243.hdf5\n","Epoch 32/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9698 - acc: 0.9824 - val_loss: 12.0354 - val_acc: 0.9289\n","\n","Epoch 00032: acc did not improve from 0.98243\n","Epoch 33/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9375 - acc: 0.9824 - val_loss: 12.8004 - val_acc: 0.9309\n","\n","Epoch 00033: acc did not improve from 0.98243\n","Epoch 34/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9286 - acc: 0.9824 - val_loss: 12.3946 - val_acc: 0.9292\n","\n","Epoch 00034: acc did not improve from 0.98243\n","Epoch 35/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.9122 - acc: 0.9824 - val_loss: 12.2538 - val_acc: 0.9193\n","\n","Epoch 00035: acc did not improve from 0.98243\n","Epoch 36/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8993 - acc: 0.9825 - val_loss: 11.3787 - val_acc: 0.9309\n","\n","Epoch 00036: acc improved from 0.98243 to 0.98247, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/36_0.98247.hdf5\n","Epoch 37/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8698 - acc: 0.9824 - val_loss: 11.8378 - val_acc: 0.9262\n","\n","Epoch 00037: acc did not improve from 0.98247\n","Epoch 38/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8634 - acc: 0.9824 - val_loss: 11.7500 - val_acc: 0.9294\n","\n","Epoch 00038: acc did not improve from 0.98247\n","Epoch 39/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8647 - acc: 0.9825 - val_loss: 11.5940 - val_acc: 0.9294\n","\n","Epoch 00039: acc improved from 0.98247 to 0.98248, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/39_0.98248.hdf5\n","Epoch 40/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.8184 - acc: 0.9824 - val_loss: 12.0892 - val_acc: 0.9374\n","\n","Epoch 00040: acc did not improve from 0.98248\n","Epoch 41/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8208 - acc: 0.9826 - val_loss: 11.9533 - val_acc: 0.9331\n","\n","Epoch 00041: acc improved from 0.98248 to 0.98262, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/41_0.98262.hdf5\n","Epoch 42/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8090 - acc: 0.9823 - val_loss: 11.7202 - val_acc: 0.9354\n","\n","Epoch 00042: acc did not improve from 0.98262\n","Epoch 43/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7982 - acc: 0.9827 - val_loss: 12.1421 - val_acc: 0.9210\n","\n","Epoch 00043: acc improved from 0.98262 to 0.98265, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/43_0.98265.hdf5\n","Epoch 44/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7749 - acc: 0.9826 - val_loss: 11.4152 - val_acc: 0.9331\n","\n","Epoch 00044: acc did not improve from 0.98265\n","Epoch 45/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.7713 - acc: 0.9824 - val_loss: 12.4057 - val_acc: 0.9329\n","\n","Epoch 00045: acc did not improve from 0.98265\n","Epoch 46/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7663 - acc: 0.9825 - val_loss: 11.8888 - val_acc: 0.9291\n","\n","Epoch 00046: acc did not improve from 0.98265\n","Epoch 47/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.7571 - acc: 0.9827 - val_loss: 12.4012 - val_acc: 0.9273\n","\n","Epoch 00047: acc improved from 0.98265 to 0.98272, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/47_0.98272.hdf5\n","Epoch 48/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7427 - acc: 0.9825 - val_loss: 12.3916 - val_acc: 0.9250\n","\n","Epoch 00048: acc did not improve from 0.98272\n","Epoch 49/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7287 - acc: 0.9826 - val_loss: 12.2805 - val_acc: 0.9292\n","\n","Epoch 00049: acc did not improve from 0.98272\n","Epoch 50/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.7049 - acc: 0.9826 - val_loss: 12.0943 - val_acc: 0.9332\n","\n","Epoch 00050: acc did not improve from 0.98272\n","Epoch 51/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7098 - acc: 0.9828 - val_loss: 11.4170 - val_acc: 0.9343\n","\n","Epoch 00051: acc improved from 0.98272 to 0.98280, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/51_0.98280.hdf5\n","Epoch 52/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.7440 - acc: 0.9827 - val_loss: 11.4890 - val_acc: 0.9335\n","\n","Epoch 00052: acc did not improve from 0.98280\n","Epoch 53/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6971 - acc: 0.9826 - val_loss: 12.1942 - val_acc: 0.9227\n","\n","Epoch 00053: acc did not improve from 0.98280\n","Epoch 54/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6690 - acc: 0.9828 - val_loss: 11.9692 - val_acc: 0.9250\n","\n","Epoch 00054: acc improved from 0.98280 to 0.98284, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/54_0.98284.hdf5\n","Epoch 55/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6736 - acc: 0.9827 - val_loss: 10.7895 - val_acc: 0.9330\n","\n","Epoch 00055: acc did not improve from 0.98284\n","Epoch 56/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6895 - acc: 0.9827 - val_loss: 11.6553 - val_acc: 0.9232\n","\n","Epoch 00056: acc did not improve from 0.98284\n","Epoch 57/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6693 - acc: 0.9827 - val_loss: 12.1778 - val_acc: 0.9329\n","\n","Epoch 00057: acc did not improve from 0.98284\n","Epoch 58/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6712 - acc: 0.9828 - val_loss: 11.9109 - val_acc: 0.9317\n","\n","Epoch 00058: acc did not improve from 0.98284\n","Epoch 59/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6499 - acc: 0.9828 - val_loss: 12.0772 - val_acc: 0.9300\n","\n","Epoch 00059: acc did not improve from 0.98284\n","Epoch 60/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.6308 - acc: 0.9827 - val_loss: 12.1336 - val_acc: 0.9286\n","\n","Epoch 00060: acc did not improve from 0.98284\n","Epoch 61/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6556 - acc: 0.9828 - val_loss: 11.1262 - val_acc: 0.9335\n","\n","Epoch 00061: acc did not improve from 0.98284\n","Epoch 62/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.6618 - acc: 0.9828 - val_loss: 11.7378 - val_acc: 0.9265\n","\n","Epoch 00062: acc did not improve from 0.98284\n","Epoch 63/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6238 - acc: 0.9827 - val_loss: 10.9887 - val_acc: 0.9276\n","\n","Epoch 00063: acc did not improve from 0.98284\n","Epoch 64/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6271 - acc: 0.9828 - val_loss: 11.2104 - val_acc: 0.9342\n","\n","Epoch 00064: acc did not improve from 0.98284\n","Epoch 65/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6048 - acc: 0.9828 - val_loss: 11.4338 - val_acc: 0.9289\n","\n","Epoch 00065: acc did not improve from 0.98284\n","Epoch 66/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5847 - acc: 0.9828 - val_loss: 12.4824 - val_acc: 0.9238\n","\n","Epoch 00066: acc did not improve from 0.98284\n","Epoch 67/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.6307 - acc: 0.9829 - val_loss: 12.4284 - val_acc: 0.9292\n","\n","Epoch 00067: acc improved from 0.98284 to 0.98288, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/67_0.98288.hdf5\n","Epoch 68/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5739 - acc: 0.9828 - val_loss: 12.3017 - val_acc: 0.9247\n","\n","Epoch 00068: acc did not improve from 0.98288\n","Epoch 69/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5802 - acc: 0.9826 - val_loss: 11.5990 - val_acc: 0.9275\n","\n","Epoch 00069: acc did not improve from 0.98288\n","Epoch 70/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6007 - acc: 0.9827 - val_loss: 11.0348 - val_acc: 0.9282\n","\n","Epoch 00070: acc did not improve from 0.98288\n","Epoch 71/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5630 - acc: 0.9827 - val_loss: 11.5115 - val_acc: 0.9316\n","\n","Epoch 00071: acc did not improve from 0.98288\n","Epoch 72/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5717 - acc: 0.9828 - val_loss: 11.9145 - val_acc: 0.9256\n","\n","Epoch 00072: acc did not improve from 0.98288\n","Epoch 73/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.5693 - acc: 0.9829 - val_loss: 12.0732 - val_acc: 0.9262\n","\n","Epoch 00073: acc improved from 0.98288 to 0.98288, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/73_0.98288.hdf5\n","Epoch 74/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5629 - acc: 0.9828 - val_loss: 11.9462 - val_acc: 0.9237\n","\n","Epoch 00074: acc did not improve from 0.98288\n","Epoch 75/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5719 - acc: 0.9828 - val_loss: 11.8004 - val_acc: 0.9293\n","\n","Epoch 00075: acc did not improve from 0.98288\n","Epoch 76/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5505 - acc: 0.9827 - val_loss: 11.6356 - val_acc: 0.9242\n","\n","Epoch 00076: acc did not improve from 0.98288\n","Epoch 77/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5495 - acc: 0.9828 - val_loss: 11.0551 - val_acc: 0.9326\n","\n","Epoch 00077: acc did not improve from 0.98288\n","Epoch 78/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5281 - acc: 0.9827 - val_loss: 11.3729 - val_acc: 0.9397\n","\n","Epoch 00078: acc did not improve from 0.98288\n","Epoch 79/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.5392 - acc: 0.9828 - val_loss: 12.5079 - val_acc: 0.9299\n","\n","Epoch 00079: acc did not improve from 0.98288\n","Epoch 80/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5221 - acc: 0.9827 - val_loss: 11.7720 - val_acc: 0.9349\n","\n","Epoch 00080: acc did not improve from 0.98288\n","Epoch 81/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5173 - acc: 0.9829 - val_loss: 12.0435 - val_acc: 0.9370\n","\n","Epoch 00081: acc did not improve from 0.98288\n","Epoch 82/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.5147 - acc: 0.9828 - val_loss: 11.2210 - val_acc: 0.9324\n","\n","Epoch 00082: acc did not improve from 0.98288\n","Epoch 83/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5353 - acc: 0.9827 - val_loss: 12.0145 - val_acc: 0.9257\n","\n","Epoch 00083: acc did not improve from 0.98288\n","Epoch 84/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5195 - acc: 0.9827 - val_loss: 12.2108 - val_acc: 0.9217\n","\n","Epoch 00084: acc did not improve from 0.98288\n","Epoch 85/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5032 - acc: 0.9825 - val_loss: 11.3917 - val_acc: 0.9321\n","\n","Epoch 00085: acc did not improve from 0.98288\n","Epoch 86/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5057 - acc: 0.9826 - val_loss: 12.0616 - val_acc: 0.9211\n","\n","Epoch 00086: acc did not improve from 0.98288\n","Epoch 87/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.5019 - acc: 0.9827 - val_loss: 12.4779 - val_acc: 0.9236\n","\n","Epoch 00087: acc did not improve from 0.98288\n","Epoch 88/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5104 - acc: 0.9828 - val_loss: 11.9865 - val_acc: 0.9252\n","\n","Epoch 00088: acc did not improve from 0.98288\n","Epoch 89/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4946 - acc: 0.9828 - val_loss: 12.5298 - val_acc: 0.9200\n","\n","Epoch 00089: acc did not improve from 0.98288\n","Epoch 90/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4993 - acc: 0.9828 - val_loss: 11.2220 - val_acc: 0.9323\n","\n","Epoch 00090: acc did not improve from 0.98288\n","Epoch 91/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4766 - acc: 0.9829 - val_loss: 13.0427 - val_acc: 0.9167\n","\n","Epoch 00091: acc improved from 0.98288 to 0.98293, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/91_0.98293.hdf5\n","Epoch 92/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4724 - acc: 0.9826 - val_loss: 11.7246 - val_acc: 0.9275\n","\n","Epoch 00092: acc did not improve from 0.98293\n","Epoch 93/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5206 - acc: 0.9826 - val_loss: 11.6258 - val_acc: 0.9399\n","\n","Epoch 00093: acc did not improve from 0.98293\n","Epoch 94/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4799 - acc: 0.9829 - val_loss: 12.1697 - val_acc: 0.9330\n","\n","Epoch 00094: acc did not improve from 0.98293\n","Epoch 95/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4664 - acc: 0.9826 - val_loss: 11.8754 - val_acc: 0.9240\n","\n","Epoch 00095: acc did not improve from 0.98293\n","Epoch 96/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4773 - acc: 0.9828 - val_loss: 12.1235 - val_acc: 0.9265\n","\n","Epoch 00096: acc did not improve from 0.98293\n","Epoch 97/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4760 - acc: 0.9827 - val_loss: 12.1213 - val_acc: 0.9277\n","\n","Epoch 00097: acc did not improve from 0.98293\n","Epoch 98/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4813 - acc: 0.9826 - val_loss: 11.6837 - val_acc: 0.9268\n","\n","Epoch 00098: acc did not improve from 0.98293\n","Epoch 99/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5077 - acc: 0.9825 - val_loss: 12.0526 - val_acc: 0.9321\n","\n","Epoch 00099: acc did not improve from 0.98293\n","Epoch 100/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4331 - acc: 0.9828 - val_loss: 12.1840 - val_acc: 0.9242\n","\n","Epoch 00100: acc did not improve from 0.98293\n","Epoch 101/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4312 - acc: 0.9828 - val_loss: 12.0732 - val_acc: 0.9316\n","\n","Epoch 00101: acc did not improve from 0.98293\n","Epoch 102/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4845 - acc: 0.9826 - val_loss: 11.9349 - val_acc: 0.9368\n","\n","Epoch 00102: acc did not improve from 0.98293\n","Epoch 103/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4489 - acc: 0.9826 - val_loss: 11.4930 - val_acc: 0.9330\n","\n","Epoch 00103: acc did not improve from 0.98293\n","Epoch 104/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4196 - acc: 0.9827 - val_loss: 12.4414 - val_acc: 0.9232\n","\n","Epoch 00104: acc did not improve from 0.98293\n","Epoch 105/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5110 - acc: 0.9826 - val_loss: 11.4494 - val_acc: 0.9283\n","\n","Epoch 00105: acc did not improve from 0.98293\n","Epoch 106/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4229 - acc: 0.9827 - val_loss: 11.4003 - val_acc: 0.9236\n","\n","Epoch 00106: acc did not improve from 0.98293\n","Epoch 107/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3987 - acc: 0.9828 - val_loss: 13.2966 - val_acc: 0.9199\n","\n","Epoch 00107: acc did not improve from 0.98293\n","Epoch 108/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4326 - acc: 0.9826 - val_loss: 11.2192 - val_acc: 0.9393\n","\n","Epoch 00108: acc did not improve from 0.98293\n","Epoch 109/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4104 - acc: 0.9825 - val_loss: 11.8378 - val_acc: 0.9296\n","\n","Epoch 00109: acc did not improve from 0.98293\n","Epoch 110/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5332 - acc: 0.9824 - val_loss: 11.2108 - val_acc: 0.9320\n","\n","Epoch 00110: acc did not improve from 0.98293\n","Epoch 111/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4799 - acc: 0.9824 - val_loss: 11.5246 - val_acc: 0.9274\n","\n","Epoch 00111: acc did not improve from 0.98293\n","Epoch 112/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3902 - acc: 0.9827 - val_loss: 11.9220 - val_acc: 0.9359\n","\n","Epoch 00112: acc did not improve from 0.98293\n","Epoch 113/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4288 - acc: 0.9823 - val_loss: 11.7042 - val_acc: 0.9433\n","\n","Epoch 00113: acc did not improve from 0.98293\n","Epoch 114/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4521 - acc: 0.9824 - val_loss: 11.8929 - val_acc: 0.9248\n","\n","Epoch 00114: acc did not improve from 0.98293\n","Epoch 115/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3911 - acc: 0.9826 - val_loss: 11.4295 - val_acc: 0.9267\n","\n","Epoch 00115: acc did not improve from 0.98293\n","Epoch 116/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3887 - acc: 0.9825 - val_loss: 11.9522 - val_acc: 0.9294\n","\n","Epoch 00116: acc did not improve from 0.98293\n","Epoch 117/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4142 - acc: 0.9825 - val_loss: 13.1112 - val_acc: 0.9234\n","\n","Epoch 00117: acc did not improve from 0.98293\n","Epoch 118/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4905 - acc: 0.9824 - val_loss: 12.4282 - val_acc: 0.9261\n","\n","Epoch 00118: acc did not improve from 0.98293\n","Epoch 119/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4173 - acc: 0.9827 - val_loss: 11.4522 - val_acc: 0.9252\n","\n","Epoch 00119: acc did not improve from 0.98293\n","Epoch 120/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3733 - acc: 0.9826 - val_loss: 12.2425 - val_acc: 0.9294\n","\n","Epoch 00120: acc did not improve from 0.98293\n","Epoch 121/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4423 - acc: 0.9824 - val_loss: 13.5886 - val_acc: 0.9283\n","\n","Epoch 00121: acc did not improve from 0.98293\n","Epoch 122/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4252 - acc: 0.9826 - val_loss: 11.8803 - val_acc: 0.9231\n","\n","Epoch 00122: acc did not improve from 0.98293\n","Epoch 123/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4252 - acc: 0.9822 - val_loss: 12.4454 - val_acc: 0.9214\n","\n","Epoch 00123: acc did not improve from 0.98293\n","Epoch 124/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3943 - acc: 0.9824 - val_loss: 12.0835 - val_acc: 0.9203\n","\n","Epoch 00124: acc did not improve from 0.98293\n","Epoch 125/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3947 - acc: 0.9824 - val_loss: 12.3150 - val_acc: 0.9276\n","\n","Epoch 00125: acc did not improve from 0.98293\n","Epoch 126/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4253 - acc: 0.9824 - val_loss: 11.6226 - val_acc: 0.9267\n","\n","Epoch 00126: acc did not improve from 0.98293\n","Epoch 127/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4103 - acc: 0.9825 - val_loss: 12.6636 - val_acc: 0.9162\n","\n","Epoch 00127: acc did not improve from 0.98293\n","Epoch 128/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3954 - acc: 0.9824 - val_loss: 11.6021 - val_acc: 0.9211\n","\n","Epoch 00128: acc did not improve from 0.98293\n","Epoch 129/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3853 - acc: 0.9826 - val_loss: 11.2142 - val_acc: 0.9222\n","\n","Epoch 00129: acc did not improve from 0.98293\n","Epoch 130/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3382 - acc: 0.9827 - val_loss: 12.2631 - val_acc: 0.9251\n","\n","Epoch 00130: acc did not improve from 0.98293\n","Epoch 131/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3842 - acc: 0.9825 - val_loss: 11.7713 - val_acc: 0.9244\n","\n","Epoch 00131: acc did not improve from 0.98293\n","Epoch 132/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3918 - acc: 0.9824 - val_loss: 12.0903 - val_acc: 0.9243\n","\n","Epoch 00132: acc did not improve from 0.98293\n","Epoch 133/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4247 - acc: 0.9826 - val_loss: 11.4189 - val_acc: 0.9259\n","\n","Epoch 00133: acc did not improve from 0.98293\n","Epoch 134/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3652 - acc: 0.9826 - val_loss: 10.9946 - val_acc: 0.9368\n","\n","Epoch 00134: acc did not improve from 0.98293\n","Epoch 135/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3929 - acc: 0.9827 - val_loss: 11.3196 - val_acc: 0.9286\n","\n","Epoch 00135: acc did not improve from 0.98293\n","Epoch 136/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4292 - acc: 0.9825 - val_loss: 11.9638 - val_acc: 0.9154\n","\n","Epoch 00136: acc did not improve from 0.98293\n","Epoch 137/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3571 - acc: 0.9826 - val_loss: 12.0675 - val_acc: 0.9272\n","\n","Epoch 00137: acc did not improve from 0.98293\n","Epoch 138/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3572 - acc: 0.9827 - val_loss: 12.2263 - val_acc: 0.9292\n","\n","Epoch 00138: acc did not improve from 0.98293\n","Epoch 139/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4248 - acc: 0.9824 - val_loss: 11.1630 - val_acc: 0.9213\n","\n","Epoch 00139: acc did not improve from 0.98293\n","Epoch 140/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3743 - acc: 0.9826 - val_loss: 11.9669 - val_acc: 0.9185\n","\n","Epoch 00140: acc did not improve from 0.98293\n","Epoch 141/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3466 - acc: 0.9826 - val_loss: 12.0966 - val_acc: 0.9215\n","\n","Epoch 00141: acc did not improve from 0.98293\n","Epoch 142/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3665 - acc: 0.9826 - val_loss: 12.7379 - val_acc: 0.9140\n","\n","Epoch 00142: acc did not improve from 0.98293\n","Epoch 143/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3439 - acc: 0.9826 - val_loss: 11.6529 - val_acc: 0.9216\n","\n","Epoch 00143: acc did not improve from 0.98293\n","Epoch 144/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3487 - acc: 0.9826 - val_loss: 12.1054 - val_acc: 0.9290\n","\n","Epoch 00144: acc did not improve from 0.98293\n","Epoch 145/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3350 - acc: 0.9827 - val_loss: 12.3142 - val_acc: 0.9222\n","\n","Epoch 00145: acc did not improve from 0.98293\n","Epoch 146/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3819 - acc: 0.9825 - val_loss: 11.3626 - val_acc: 0.9234\n","\n","Epoch 00146: acc did not improve from 0.98293\n","Epoch 147/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3395 - acc: 0.9828 - val_loss: 12.2291 - val_acc: 0.9220\n","\n","Epoch 00147: acc did not improve from 0.98293\n","Epoch 148/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3526 - acc: 0.9827 - val_loss: 11.2152 - val_acc: 0.9220\n","\n","Epoch 00148: acc did not improve from 0.98293\n","Epoch 149/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4604 - acc: 0.9823 - val_loss: 11.6623 - val_acc: 0.9216\n","\n","Epoch 00149: acc did not improve from 0.98293\n","Epoch 150/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3568 - acc: 0.9825 - val_loss: 11.5325 - val_acc: 0.9183\n","\n","Epoch 00150: acc did not improve from 0.98293\n","Epoch 151/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3334 - acc: 0.9825 - val_loss: 11.4854 - val_acc: 0.9308\n","\n","Epoch 00151: acc did not improve from 0.98293\n","Epoch 152/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3978 - acc: 0.9825 - val_loss: 12.1221 - val_acc: 0.9185\n","\n","Epoch 00152: acc did not improve from 0.98293\n","Epoch 153/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3161 - acc: 0.9827 - val_loss: 12.5377 - val_acc: 0.9214\n","\n","Epoch 00153: acc did not improve from 0.98293\n","Epoch 154/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3146 - acc: 0.9826 - val_loss: 11.3351 - val_acc: 0.9408\n","\n","Epoch 00154: acc did not improve from 0.98293\n","Epoch 155/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3603 - acc: 0.9825 - val_loss: 11.6392 - val_acc: 0.9350\n","\n","Epoch 00155: acc did not improve from 0.98293\n","Epoch 156/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2932 - acc: 0.9829 - val_loss: 11.8094 - val_acc: 0.9285\n","\n","Epoch 00156: acc did not improve from 0.98293\n","Epoch 157/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3725 - acc: 0.9824 - val_loss: 12.1800 - val_acc: 0.9167\n","\n","Epoch 00157: acc did not improve from 0.98293\n","Epoch 158/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3825 - acc: 0.9825 - val_loss: 11.9420 - val_acc: 0.9282\n","\n","Epoch 00158: acc did not improve from 0.98293\n","Epoch 159/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3613 - acc: 0.9825 - val_loss: 11.7892 - val_acc: 0.9244\n","\n","Epoch 00159: acc did not improve from 0.98293\n","Epoch 160/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3407 - acc: 0.9826 - val_loss: 12.0659 - val_acc: 0.9283\n","\n","Epoch 00160: acc did not improve from 0.98293\n","Epoch 161/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2969 - acc: 0.9827 - val_loss: 11.4908 - val_acc: 0.9314\n","\n","Epoch 00161: acc did not improve from 0.98293\n","Epoch 162/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3505 - acc: 0.9826 - val_loss: 12.0606 - val_acc: 0.9238\n","\n","Epoch 00162: acc did not improve from 0.98293\n","Epoch 163/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3034 - acc: 0.9825 - val_loss: 11.6518 - val_acc: 0.9260\n","\n","Epoch 00163: acc did not improve from 0.98293\n","Epoch 164/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4378 - acc: 0.9823 - val_loss: 11.9668 - val_acc: 0.9308\n","\n","Epoch 00164: acc did not improve from 0.98293\n","Epoch 165/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3137 - acc: 0.9827 - val_loss: 11.2216 - val_acc: 0.9306\n","\n","Epoch 00165: acc did not improve from 0.98293\n","Epoch 166/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3506 - acc: 0.9824 - val_loss: 11.2878 - val_acc: 0.9244\n","\n","Epoch 00166: acc did not improve from 0.98293\n","Epoch 167/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3474 - acc: 0.9826 - val_loss: 11.6986 - val_acc: 0.9179\n","\n","Epoch 00167: acc did not improve from 0.98293\n","Epoch 168/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3176 - acc: 0.9826 - val_loss: 11.1513 - val_acc: 0.9216\n","\n","Epoch 00168: acc did not improve from 0.98293\n","Epoch 169/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3375 - acc: 0.9826 - val_loss: 12.2715 - val_acc: 0.9180\n","\n","Epoch 00169: acc did not improve from 0.98293\n","Epoch 170/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2726 - acc: 0.9826 - val_loss: 11.3669 - val_acc: 0.9236\n","\n","Epoch 00170: acc did not improve from 0.98293\n","Epoch 171/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3168 - acc: 0.9825 - val_loss: 11.9227 - val_acc: 0.9295\n","\n","Epoch 00171: acc did not improve from 0.98293\n","Epoch 172/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3006 - acc: 0.9826 - val_loss: 11.3276 - val_acc: 0.9287\n","\n","Epoch 00172: acc did not improve from 0.98293\n","Epoch 173/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4518 - acc: 0.9822 - val_loss: 12.2548 - val_acc: 0.9137\n","\n","Epoch 00173: acc did not improve from 0.98293\n","Epoch 174/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2890 - acc: 0.9824 - val_loss: 12.3768 - val_acc: 0.9127\n","\n","Epoch 00174: acc did not improve from 0.98293\n","Epoch 175/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3038 - acc: 0.9827 - val_loss: 11.8995 - val_acc: 0.9215\n","\n","Epoch 00175: acc did not improve from 0.98293\n","Epoch 176/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3302 - acc: 0.9825 - val_loss: 12.6556 - val_acc: 0.9222\n","\n","Epoch 00176: acc did not improve from 0.98293\n","Epoch 177/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3298 - acc: 0.9825 - val_loss: 11.3522 - val_acc: 0.9264\n","\n","Epoch 00177: acc did not improve from 0.98293\n","Epoch 178/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3426 - acc: 0.9825 - val_loss: 11.8028 - val_acc: 0.9229\n","\n","Epoch 00178: acc did not improve from 0.98293\n","Epoch 179/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3283 - acc: 0.9826 - val_loss: 12.2228 - val_acc: 0.9315\n","\n","Epoch 00179: acc did not improve from 0.98293\n","Epoch 180/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2639 - acc: 0.9828 - val_loss: 12.0288 - val_acc: 0.9254\n","\n","Epoch 00180: acc did not improve from 0.98293\n","Epoch 181/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4374 - acc: 0.9823 - val_loss: 12.1274 - val_acc: 0.9176\n","\n","Epoch 00181: acc did not improve from 0.98293\n","Epoch 182/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2918 - acc: 0.9825 - val_loss: 11.1589 - val_acc: 0.9365\n","\n","Epoch 00182: acc did not improve from 0.98293\n","Epoch 183/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2698 - acc: 0.9827 - val_loss: 12.0183 - val_acc: 0.9385\n","\n","Epoch 00183: acc did not improve from 0.98293\n","Epoch 184/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3345 - acc: 0.9825 - val_loss: 12.0258 - val_acc: 0.9204\n","\n","Epoch 00184: acc did not improve from 0.98293\n","Epoch 185/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2884 - acc: 0.9826 - val_loss: 11.3757 - val_acc: 0.9315\n","\n","Epoch 00185: acc did not improve from 0.98293\n","Epoch 186/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4597 - acc: 0.9822 - val_loss: 12.1097 - val_acc: 0.9199\n","\n","Epoch 00186: acc did not improve from 0.98293\n","Epoch 187/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2372 - acc: 0.9826 - val_loss: 11.7014 - val_acc: 0.9276\n","\n","Epoch 00187: acc did not improve from 0.98293\n","Epoch 188/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2501 - acc: 0.9826 - val_loss: 11.4655 - val_acc: 0.9217\n","\n","Epoch 00188: acc did not improve from 0.98293\n","Epoch 189/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2641 - acc: 0.9828 - val_loss: 11.7511 - val_acc: 0.9191\n","\n","Epoch 00189: acc did not improve from 0.98293\n","Epoch 190/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2766 - acc: 0.9826 - val_loss: 12.0613 - val_acc: 0.9234\n","\n","Epoch 00190: acc did not improve from 0.98293\n","Epoch 191/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3401 - acc: 0.9822 - val_loss: 12.9002 - val_acc: 0.9268\n","\n","Epoch 00191: acc did not improve from 0.98293\n","Epoch 192/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3473 - acc: 0.9823 - val_loss: 11.5820 - val_acc: 0.9200\n","\n","Epoch 00192: acc did not improve from 0.98293\n","Epoch 193/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2474 - acc: 0.9826 - val_loss: 11.6377 - val_acc: 0.9300\n","\n","Epoch 00193: acc did not improve from 0.98293\n","Epoch 194/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.5207 - acc: 0.9821 - val_loss: 11.9664 - val_acc: 0.9232\n","\n","Epoch 00194: acc did not improve from 0.98293\n","Epoch 195/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2541 - acc: 0.9827 - val_loss: 12.1248 - val_acc: 0.9285\n","\n","Epoch 00195: acc did not improve from 0.98293\n","Epoch 196/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2913 - acc: 0.9825 - val_loss: 11.4074 - val_acc: 0.9229\n","\n","Epoch 00196: acc did not improve from 0.98293\n","Epoch 197/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2622 - acc: 0.9826 - val_loss: 11.2475 - val_acc: 0.9291\n","\n","Epoch 00197: acc did not improve from 0.98293\n","Epoch 198/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2259 - acc: 0.9827 - val_loss: 12.0986 - val_acc: 0.9345\n","\n","Epoch 00198: acc did not improve from 0.98293\n","Epoch 199/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2541 - acc: 0.9826 - val_loss: 12.3637 - val_acc: 0.9321\n","\n","Epoch 00199: acc did not improve from 0.98293\n","Epoch 200/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3629 - acc: 0.9824 - val_loss: 11.5691 - val_acc: 0.9313\n","\n","Epoch 00200: acc did not improve from 0.98293\n","Epoch 201/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4200 - acc: 0.9823 - val_loss: 11.7789 - val_acc: 0.9302\n","\n","Epoch 00201: acc did not improve from 0.98293\n","Epoch 202/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2666 - acc: 0.9826 - val_loss: 12.8768 - val_acc: 0.9156\n","\n","Epoch 00202: acc did not improve from 0.98293\n","Epoch 203/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2539 - acc: 0.9829 - val_loss: 12.1946 - val_acc: 0.9200\n","\n","Epoch 00203: acc did not improve from 0.98293\n","Epoch 204/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2967 - acc: 0.9826 - val_loss: 12.4074 - val_acc: 0.9176\n","\n","Epoch 00204: acc did not improve from 0.98293\n","Epoch 205/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3474 - acc: 0.9826 - val_loss: 11.6086 - val_acc: 0.9299\n","\n","Epoch 00205: acc did not improve from 0.98293\n","Epoch 206/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2233 - acc: 0.9827 - val_loss: 11.8564 - val_acc: 0.9330\n","\n","Epoch 00206: acc did not improve from 0.98293\n","Epoch 207/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2382 - acc: 0.9827 - val_loss: 12.0704 - val_acc: 0.9317\n","\n","Epoch 00207: acc did not improve from 0.98293\n","Epoch 208/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.5339 - acc: 0.9822 - val_loss: 11.3249 - val_acc: 0.9295\n","\n","Epoch 00208: acc did not improve from 0.98293\n","Epoch 209/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2416 - acc: 0.9826 - val_loss: 11.0906 - val_acc: 0.9360\n","\n","Epoch 00209: acc did not improve from 0.98293\n","Epoch 210/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3772 - acc: 0.9823 - val_loss: 12.0720 - val_acc: 0.9247\n","\n","Epoch 00210: acc did not improve from 0.98293\n","Epoch 211/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2316 - acc: 0.9827 - val_loss: 12.6591 - val_acc: 0.9193\n","\n","Epoch 00211: acc did not improve from 0.98293\n","Epoch 212/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3059 - acc: 0.9826 - val_loss: 11.7836 - val_acc: 0.9272\n","\n","Epoch 00212: acc did not improve from 0.98293\n","Epoch 213/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2102 - acc: 0.9829 - val_loss: 11.4980 - val_acc: 0.9334\n","\n","Epoch 00213: acc did not improve from 0.98293\n","Epoch 214/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3061 - acc: 0.9825 - val_loss: 12.3294 - val_acc: 0.9157\n","\n","Epoch 00214: acc did not improve from 0.98293\n","Epoch 215/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2687 - acc: 0.9827 - val_loss: 11.4438 - val_acc: 0.9317\n","\n","Epoch 00215: acc did not improve from 0.98293\n","Epoch 216/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3186 - acc: 0.9826 - val_loss: 12.4582 - val_acc: 0.9199\n","\n","Epoch 00216: acc did not improve from 0.98293\n","Epoch 217/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2764 - acc: 0.9823 - val_loss: 11.7329 - val_acc: 0.9252\n","\n","Epoch 00217: acc did not improve from 0.98293\n","Epoch 218/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2994 - acc: 0.9827 - val_loss: 11.8337 - val_acc: 0.9266\n","\n","Epoch 00218: acc did not improve from 0.98293\n","Epoch 219/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2418 - acc: 0.9829 - val_loss: 12.5030 - val_acc: 0.9155\n","\n","Epoch 00219: acc did not improve from 0.98293\n","Epoch 220/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2874 - acc: 0.9824 - val_loss: 12.0763 - val_acc: 0.9342\n","\n","Epoch 00220: acc did not improve from 0.98293\n","Epoch 221/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2552 - acc: 0.9827 - val_loss: 11.9658 - val_acc: 0.9278\n","\n","Epoch 00221: acc did not improve from 0.98293\n","Epoch 222/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2242 - acc: 0.9827 - val_loss: 11.5786 - val_acc: 0.9214\n","\n","Epoch 00222: acc did not improve from 0.98293\n","Epoch 223/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2115 - acc: 0.9828 - val_loss: 12.1038 - val_acc: 0.9178\n","\n","Epoch 00223: acc did not improve from 0.98293\n","Epoch 224/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3899 - acc: 0.9822 - val_loss: 12.1784 - val_acc: 0.9286\n","\n","Epoch 00224: acc did not improve from 0.98293\n","Epoch 225/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3768 - acc: 0.9825 - val_loss: 11.5920 - val_acc: 0.9304\n","\n","Epoch 00225: acc did not improve from 0.98293\n","Epoch 226/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1967 - acc: 0.9829 - val_loss: 12.5561 - val_acc: 0.9131\n","\n","Epoch 00226: acc did not improve from 0.98293\n","Epoch 227/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2125 - acc: 0.9828 - val_loss: 11.0779 - val_acc: 0.9369\n","\n","Epoch 00227: acc did not improve from 0.98293\n","Epoch 228/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2909 - acc: 0.9826 - val_loss: 12.5053 - val_acc: 0.9113\n","\n","Epoch 00228: acc did not improve from 0.98293\n","Epoch 229/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2981 - acc: 0.9826 - val_loss: 12.5598 - val_acc: 0.9226\n","\n","Epoch 00229: acc did not improve from 0.98293\n","Epoch 230/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3468 - acc: 0.9824 - val_loss: 11.3386 - val_acc: 0.9271\n","\n","Epoch 00230: acc did not improve from 0.98293\n","Epoch 231/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2269 - acc: 0.9828 - val_loss: 12.4646 - val_acc: 0.9150\n","\n","Epoch 00231: acc did not improve from 0.98293\n","Epoch 232/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1748 - acc: 0.9829 - val_loss: 12.6225 - val_acc: 0.9157\n","\n","Epoch 00232: acc did not improve from 0.98293\n","Epoch 233/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2721 - acc: 0.9826 - val_loss: 12.5091 - val_acc: 0.9276\n","\n","Epoch 00233: acc did not improve from 0.98293\n","Epoch 234/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6202 - acc: 0.9816 - val_loss: 11.8082 - val_acc: 0.9150\n","\n","Epoch 00234: acc did not improve from 0.98293\n","Epoch 235/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2406 - acc: 0.9825 - val_loss: 11.3778 - val_acc: 0.9340\n","\n","Epoch 00235: acc did not improve from 0.98293\n","Epoch 236/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2736 - acc: 0.9828 - val_loss: 11.2479 - val_acc: 0.9219\n","\n","Epoch 00236: acc did not improve from 0.98293\n","Epoch 237/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3135 - acc: 0.9825 - val_loss: 12.2775 - val_acc: 0.9306\n","\n","Epoch 00237: acc did not improve from 0.98293\n","Epoch 238/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2669 - acc: 0.9826 - val_loss: 12.1699 - val_acc: 0.9166\n","\n","Epoch 00238: acc did not improve from 0.98293\n","Epoch 239/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2182 - acc: 0.9825 - val_loss: 11.0887 - val_acc: 0.9368\n","\n","Epoch 00239: acc did not improve from 0.98293\n","Epoch 240/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4066 - acc: 0.9822 - val_loss: 11.9070 - val_acc: 0.9304\n","\n","Epoch 00240: acc did not improve from 0.98293\n","Epoch 241/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2573 - acc: 0.9826 - val_loss: 12.3743 - val_acc: 0.9077\n","\n","Epoch 00241: acc did not improve from 0.98293\n","Epoch 242/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4094 - acc: 0.9822 - val_loss: 12.9724 - val_acc: 0.9102\n","\n","Epoch 00242: acc did not improve from 0.98293\n","Epoch 243/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2337 - acc: 0.9827 - val_loss: 12.9338 - val_acc: 0.9141\n","\n","Epoch 00243: acc did not improve from 0.98293\n","Epoch 244/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2106 - acc: 0.9830 - val_loss: 11.0048 - val_acc: 0.9224\n","\n","Epoch 00244: acc improved from 0.98293 to 0.98296, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/244_0.98296.hdf5\n","Epoch 245/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.4900 - acc: 0.9821 - val_loss: 11.7283 - val_acc: 0.9338\n","\n","Epoch 00245: acc did not improve from 0.98296\n","Epoch 246/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3729 - acc: 0.9821 - val_loss: 11.8516 - val_acc: 0.9217\n","\n","Epoch 00246: acc did not improve from 0.98296\n","Epoch 247/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.1760 - acc: 0.9830 - val_loss: 11.7652 - val_acc: 0.9223\n","\n","Epoch 00247: acc improved from 0.98296 to 0.98301, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/247_0.98301.hdf5\n","Epoch 248/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2917 - acc: 0.9824 - val_loss: 12.6689 - val_acc: 0.9168\n","\n","Epoch 00248: acc did not improve from 0.98301\n","Epoch 249/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2374 - acc: 0.9826 - val_loss: 11.9440 - val_acc: 0.9163\n","\n","Epoch 00249: acc did not improve from 0.98301\n","Epoch 250/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3496 - acc: 0.9824 - val_loss: 12.0535 - val_acc: 0.9134\n","\n","Epoch 00250: acc did not improve from 0.98301\n","Epoch 251/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2964 - acc: 0.9827 - val_loss: 11.9959 - val_acc: 0.9153\n","\n","Epoch 00251: acc did not improve from 0.98301\n","Epoch 252/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3273 - acc: 0.9825 - val_loss: 12.1207 - val_acc: 0.9203\n","\n","Epoch 00252: acc did not improve from 0.98301\n","Epoch 253/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.1886 - acc: 0.9829 - val_loss: 12.4176 - val_acc: 0.9051\n","\n","Epoch 00253: acc did not improve from 0.98301\n","Epoch 254/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2114 - acc: 0.9828 - val_loss: 13.2748 - val_acc: 0.9048\n","\n","Epoch 00254: acc did not improve from 0.98301\n","Epoch 255/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2042 - acc: 0.9827 - val_loss: 12.3028 - val_acc: 0.9097\n","\n","Epoch 00255: acc did not improve from 0.98301\n","Epoch 256/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4546 - acc: 0.9821 - val_loss: 11.5155 - val_acc: 0.9321\n","\n","Epoch 00256: acc did not improve from 0.98301\n","Epoch 257/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2224 - acc: 0.9827 - val_loss: 12.2228 - val_acc: 0.9219\n","\n","Epoch 00257: acc did not improve from 0.98301\n","Epoch 258/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1732 - acc: 0.9828 - val_loss: 12.0350 - val_acc: 0.9174\n","\n","Epoch 00258: acc did not improve from 0.98301\n","Epoch 259/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2014 - acc: 0.9827 - val_loss: 12.0882 - val_acc: 0.9334\n","\n","Epoch 00259: acc did not improve from 0.98301\n","Epoch 260/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3248 - acc: 0.9824 - val_loss: 12.4857 - val_acc: 0.9120\n","\n","Epoch 00260: acc did not improve from 0.98301\n","Epoch 261/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.7195 - acc: 0.9813 - val_loss: 12.6065 - val_acc: 0.9145\n","\n","Epoch 00261: acc did not improve from 0.98301\n","Epoch 262/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2504 - acc: 0.9830 - val_loss: 12.5211 - val_acc: 0.9255\n","\n","Epoch 00262: acc improved from 0.98301 to 0.98302, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/262_0.98302.hdf5\n","Epoch 263/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2060 - acc: 0.9829 - val_loss: 11.9367 - val_acc: 0.9236\n","\n","Epoch 00263: acc did not improve from 0.98302\n","Epoch 264/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2121 - acc: 0.9827 - val_loss: 12.0747 - val_acc: 0.9225\n","\n","Epoch 00264: acc did not improve from 0.98302\n","Epoch 265/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1925 - acc: 0.9827 - val_loss: 13.8649 - val_acc: 0.9141\n","\n","Epoch 00265: acc did not improve from 0.98302\n","Epoch 266/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5450 - acc: 0.9818 - val_loss: 11.8534 - val_acc: 0.9235\n","\n","Epoch 00266: acc did not improve from 0.98302\n","Epoch 267/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2720 - acc: 0.9827 - val_loss: 12.7847 - val_acc: 0.9240\n","\n","Epoch 00267: acc did not improve from 0.98302\n","Epoch 268/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1981 - acc: 0.9828 - val_loss: 12.6162 - val_acc: 0.9104\n","\n","Epoch 00268: acc did not improve from 0.98302\n","Epoch 269/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2172 - acc: 0.9828 - val_loss: 11.8540 - val_acc: 0.9184\n","\n","Epoch 00269: acc did not improve from 0.98302\n","Epoch 270/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3342 - acc: 0.9824 - val_loss: 12.0610 - val_acc: 0.9173\n","\n","Epoch 00270: acc did not improve from 0.98302\n","Epoch 271/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2483 - acc: 0.9826 - val_loss: 12.3874 - val_acc: 0.9244\n","\n","Epoch 00271: acc did not improve from 0.98302\n","Epoch 272/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1630 - acc: 0.9830 - val_loss: 11.5952 - val_acc: 0.9179\n","\n","Epoch 00272: acc did not improve from 0.98302\n","Epoch 273/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6144 - acc: 0.9816 - val_loss: 11.9621 - val_acc: 0.9297\n","\n","Epoch 00273: acc did not improve from 0.98302\n","Epoch 274/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2526 - acc: 0.9825 - val_loss: 12.0306 - val_acc: 0.9101\n","\n","Epoch 00274: acc did not improve from 0.98302\n","Epoch 275/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4269 - acc: 0.9821 - val_loss: 12.1849 - val_acc: 0.9193\n","\n","Epoch 00275: acc did not improve from 0.98302\n","Epoch 276/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2026 - acc: 0.9826 - val_loss: 11.2642 - val_acc: 0.9208\n","\n","Epoch 00276: acc did not improve from 0.98302\n","Epoch 277/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2101 - acc: 0.9829 - val_loss: 12.4117 - val_acc: 0.9332\n","\n","Epoch 00277: acc did not improve from 0.98302\n","Epoch 278/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3226 - acc: 0.9825 - val_loss: 12.3175 - val_acc: 0.9132\n","\n","Epoch 00278: acc did not improve from 0.98302\n","Epoch 279/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2509 - acc: 0.9826 - val_loss: 13.1722 - val_acc: 0.9077\n","\n","Epoch 00279: acc did not improve from 0.98302\n","Epoch 280/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2009 - acc: 0.9829 - val_loss: 11.7578 - val_acc: 0.9142\n","\n","Epoch 00280: acc did not improve from 0.98302\n","Epoch 281/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2936 - acc: 0.9824 - val_loss: 12.4743 - val_acc: 0.9337\n","\n","Epoch 00281: acc did not improve from 0.98302\n","Epoch 282/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2905 - acc: 0.9826 - val_loss: 11.8480 - val_acc: 0.9239\n","\n","Epoch 00282: acc did not improve from 0.98302\n","Epoch 283/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4283 - acc: 0.9821 - val_loss: 12.2642 - val_acc: 0.9304\n","\n","Epoch 00283: acc did not improve from 0.98302\n","Epoch 284/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2629 - acc: 0.9826 - val_loss: 12.1533 - val_acc: 0.9127\n","\n","Epoch 00284: acc did not improve from 0.98302\n","Epoch 285/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2713 - acc: 0.9828 - val_loss: 12.4607 - val_acc: 0.9215\n","\n","Epoch 00285: acc did not improve from 0.98302\n","Epoch 286/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3175 - acc: 0.9825 - val_loss: 11.5392 - val_acc: 0.9310\n","\n","Epoch 00286: acc did not improve from 0.98302\n","Epoch 287/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3008 - acc: 0.9825 - val_loss: 12.1874 - val_acc: 0.9172\n","\n","Epoch 00287: acc did not improve from 0.98302\n","Epoch 288/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2206 - acc: 0.9827 - val_loss: 11.0064 - val_acc: 0.9200\n","\n","Epoch 00288: acc did not improve from 0.98302\n","Epoch 289/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1929 - acc: 0.9828 - val_loss: 12.0221 - val_acc: 0.9160\n","\n","Epoch 00289: acc did not improve from 0.98302\n","Epoch 290/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2982 - acc: 0.9825 - val_loss: 12.4227 - val_acc: 0.9103\n","\n","Epoch 00290: acc did not improve from 0.98302\n","Epoch 291/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6886 - acc: 0.9812 - val_loss: 11.7492 - val_acc: 0.9220\n","\n","Epoch 00291: acc did not improve from 0.98302\n","Epoch 292/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3052 - acc: 0.9826 - val_loss: 14.6076 - val_acc: 0.9040\n","\n","Epoch 00292: acc did not improve from 0.98302\n","Epoch 293/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1896 - acc: 0.9827 - val_loss: 12.4108 - val_acc: 0.9171\n","\n","Epoch 00293: acc did not improve from 0.98302\n","Epoch 294/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2679 - acc: 0.9829 - val_loss: 12.1969 - val_acc: 0.9140\n","\n","Epoch 00294: acc did not improve from 0.98302\n","Epoch 295/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6299 - acc: 0.9815 - val_loss: 13.7930 - val_acc: 0.9060\n","\n","Epoch 00295: acc did not improve from 0.98302\n","Epoch 296/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2131 - acc: 0.9827 - val_loss: 12.1393 - val_acc: 0.9228\n","\n","Epoch 00296: acc did not improve from 0.98302\n","Epoch 297/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2323 - acc: 0.9829 - val_loss: 11.5498 - val_acc: 0.9192\n","\n","Epoch 00297: acc did not improve from 0.98302\n","Epoch 298/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2454 - acc: 0.9829 - val_loss: 11.0637 - val_acc: 0.9306\n","\n","Epoch 00298: acc did not improve from 0.98302\n","Epoch 299/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6137 - acc: 0.9814 - val_loss: 11.0130 - val_acc: 0.9386\n","\n","Epoch 00299: acc did not improve from 0.98302\n","Epoch 300/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1642 - acc: 0.9828 - val_loss: 11.3509 - val_acc: 0.9250\n","\n","Epoch 00300: acc did not improve from 0.98302\n","Epoch 301/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3611 - acc: 0.9823 - val_loss: 14.3417 - val_acc: 0.9114\n","\n","Epoch 00301: acc did not improve from 0.98302\n","Epoch 302/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3296 - acc: 0.9824 - val_loss: 11.6401 - val_acc: 0.9197\n","\n","Epoch 00302: acc did not improve from 0.98302\n","Epoch 303/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3077 - acc: 0.9824 - val_loss: 12.0729 - val_acc: 0.9221\n","\n","Epoch 00303: acc did not improve from 0.98302\n","Epoch 304/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2332 - acc: 0.9826 - val_loss: 11.3864 - val_acc: 0.9257\n","\n","Epoch 00304: acc did not improve from 0.98302\n","Epoch 305/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2514 - acc: 0.9825 - val_loss: 11.8211 - val_acc: 0.9270\n","\n","Epoch 00305: acc did not improve from 0.98302\n","Epoch 306/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2504 - acc: 0.9825 - val_loss: 11.8051 - val_acc: 0.9122\n","\n","Epoch 00306: acc did not improve from 0.98302\n","Epoch 307/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3092 - acc: 0.9825 - val_loss: 13.0747 - val_acc: 0.9061\n","\n","Epoch 00307: acc did not improve from 0.98302\n","Epoch 308/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1539 - acc: 0.9828 - val_loss: 13.0244 - val_acc: 0.9115\n","\n","Epoch 00308: acc did not improve from 0.98302\n","Epoch 309/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1848 - acc: 0.9829 - val_loss: 12.9459 - val_acc: 0.9348\n","\n","Epoch 00309: acc did not improve from 0.98302\n","Epoch 310/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2152 - acc: 0.9826 - val_loss: 11.9970 - val_acc: 0.9342\n","\n","Epoch 00310: acc did not improve from 0.98302\n","Epoch 311/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2056 - acc: 0.9826 - val_loss: 11.9719 - val_acc: 0.9126\n","\n","Epoch 00311: acc did not improve from 0.98302\n","Epoch 312/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2401 - acc: 0.9827 - val_loss: 12.6988 - val_acc: 0.9305\n","\n","Epoch 00312: acc did not improve from 0.98302\n","Epoch 313/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2145 - acc: 0.9827 - val_loss: 11.8983 - val_acc: 0.9200\n","\n","Epoch 00313: acc did not improve from 0.98302\n","Epoch 314/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.3245 - acc: 0.9822 - val_loss: 11.6247 - val_acc: 0.9265\n","\n","Epoch 00314: acc did not improve from 0.98302\n","Epoch 315/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.1514 - acc: 0.9829 - val_loss: 11.7688 - val_acc: 0.9153\n","\n","Epoch 00315: acc did not improve from 0.98302\n","Epoch 316/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.1930 - acc: 0.9829 - val_loss: 12.1730 - val_acc: 0.9296\n","\n","Epoch 00316: acc did not improve from 0.98302\n","Epoch 317/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2586 - acc: 0.9826 - val_loss: 11.8126 - val_acc: 0.9235\n","\n","Epoch 00317: acc did not improve from 0.98302\n","Epoch 318/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2482 - acc: 0.9825 - val_loss: 13.1122 - val_acc: 0.9036\n","\n","Epoch 00318: acc did not improve from 0.98302\n","Epoch 319/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2645 - acc: 0.9824 - val_loss: 11.6249 - val_acc: 0.9144\n","\n","Epoch 00319: acc did not improve from 0.98302\n","Epoch 320/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3565 - acc: 0.9822 - val_loss: 11.6876 - val_acc: 0.9183\n","\n","Epoch 00320: acc did not improve from 0.98302\n","Epoch 321/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5489 - acc: 0.9816 - val_loss: 12.3362 - val_acc: 0.9199\n","\n","Epoch 00321: acc did not improve from 0.98302\n","Epoch 322/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1882 - acc: 0.9828 - val_loss: 12.0293 - val_acc: 0.9185\n","\n","Epoch 00322: acc did not improve from 0.98302\n","Epoch 323/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2884 - acc: 0.9823 - val_loss: 12.1133 - val_acc: 0.9190\n","\n","Epoch 00323: acc did not improve from 0.98302\n","Epoch 324/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1287 - acc: 0.9827 - val_loss: 11.9119 - val_acc: 0.9268\n","\n","Epoch 00324: acc did not improve from 0.98302\n","Epoch 325/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4744 - acc: 0.9818 - val_loss: 12.6049 - val_acc: 0.9292\n","\n","Epoch 00325: acc did not improve from 0.98302\n","Epoch 326/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2508 - acc: 0.9826 - val_loss: 11.3414 - val_acc: 0.9102\n","\n","Epoch 00326: acc did not improve from 0.98302\n","Epoch 327/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1404 - acc: 0.9830 - val_loss: 11.5296 - val_acc: 0.9311\n","\n","Epoch 00327: acc improved from 0.98302 to 0.98302, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/327_0.98302.hdf5\n","Epoch 328/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5524 - acc: 0.9813 - val_loss: 11.4285 - val_acc: 0.9290\n","\n","Epoch 00328: acc did not improve from 0.98302\n","Epoch 329/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2259 - acc: 0.9826 - val_loss: 13.2623 - val_acc: 0.9120\n","\n","Epoch 00329: acc did not improve from 0.98302\n","Epoch 330/1000\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.2033 - acc: 0.9825 - val_loss: 11.9460 - val_acc: 0.9269\n","\n","Epoch 00330: acc did not improve from 0.98302\n","Epoch 331/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2271 - acc: 0.9825 - val_loss: 11.7694 - val_acc: 0.9305\n","\n","Epoch 00331: acc did not improve from 0.98302\n","Epoch 332/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2186 - acc: 0.9826 - val_loss: 11.7691 - val_acc: 0.9118\n","\n","Epoch 00332: acc did not improve from 0.98302\n","Epoch 333/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2045 - acc: 0.9827 - val_loss: 11.9633 - val_acc: 0.9232\n","\n","Epoch 00333: acc did not improve from 0.98302\n","Epoch 334/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6197 - acc: 0.9812 - val_loss: 24.5134 - val_acc: 0.8559\n","\n","Epoch 00334: acc did not improve from 0.98302\n","Epoch 335/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8907 - acc: 0.9805 - val_loss: 12.2554 - val_acc: 0.9159\n","\n","Epoch 00335: acc did not improve from 0.98302\n","Epoch 336/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1745 - acc: 0.9829 - val_loss: 11.4633 - val_acc: 0.9132\n","\n","Epoch 00336: acc did not improve from 0.98302\n","Epoch 337/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1785 - acc: 0.9826 - val_loss: 12.1347 - val_acc: 0.9248\n","\n","Epoch 00337: acc did not improve from 0.98302\n","Epoch 338/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1996 - acc: 0.9826 - val_loss: 11.7203 - val_acc: 0.9271\n","\n","Epoch 00338: acc did not improve from 0.98302\n","Epoch 339/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1458 - acc: 0.9828 - val_loss: 12.0678 - val_acc: 0.9164\n","\n","Epoch 00339: acc did not improve from 0.98302\n","Epoch 340/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2911 - acc: 0.9823 - val_loss: 12.1162 - val_acc: 0.9098\n","\n","Epoch 00340: acc did not improve from 0.98302\n","Epoch 341/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1918 - acc: 0.9826 - val_loss: 11.5504 - val_acc: 0.9301\n","\n","Epoch 00341: acc did not improve from 0.98302\n","Epoch 342/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2688 - acc: 0.9824 - val_loss: 10.8133 - val_acc: 0.9172\n","\n","Epoch 00342: acc did not improve from 0.98302\n","Epoch 343/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3191 - acc: 0.9821 - val_loss: 12.6449 - val_acc: 0.9166\n","\n","Epoch 00343: acc did not improve from 0.98302\n","Epoch 344/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2481 - acc: 0.9826 - val_loss: 11.9269 - val_acc: 0.9281\n","\n","Epoch 00344: acc did not improve from 0.98302\n","Epoch 345/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2491 - acc: 0.9824 - val_loss: 11.3421 - val_acc: 0.9262\n","\n","Epoch 00345: acc did not improve from 0.98302\n","Epoch 346/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2083 - acc: 0.9827 - val_loss: 12.6850 - val_acc: 0.9186\n","\n","Epoch 00346: acc did not improve from 0.98302\n","Epoch 347/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6507 - acc: 0.9813 - val_loss: 12.9478 - val_acc: 0.9131\n","\n","Epoch 00347: acc did not improve from 0.98302\n","Epoch 348/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2284 - acc: 0.9826 - val_loss: 12.0444 - val_acc: 0.9304\n","\n","Epoch 00348: acc did not improve from 0.98302\n","Epoch 349/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1176 - acc: 0.9827 - val_loss: 12.1455 - val_acc: 0.9296\n","\n","Epoch 00349: acc did not improve from 0.98302\n","Epoch 350/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2154 - acc: 0.9826 - val_loss: 13.3985 - val_acc: 0.9263\n","\n","Epoch 00350: acc did not improve from 0.98302\n","Epoch 351/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2898 - acc: 0.9824 - val_loss: 12.1603 - val_acc: 0.9168\n","\n","Epoch 00351: acc did not improve from 0.98302\n","Epoch 352/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2480 - acc: 0.9825 - val_loss: 12.6483 - val_acc: 0.9157\n","\n","Epoch 00352: acc did not improve from 0.98302\n","Epoch 353/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3002 - acc: 0.9824 - val_loss: 12.3315 - val_acc: 0.9133\n","\n","Epoch 00353: acc did not improve from 0.98302\n","Epoch 354/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2741 - acc: 0.9823 - val_loss: 12.2972 - val_acc: 0.9072\n","\n","Epoch 00354: acc did not improve from 0.98302\n","Epoch 355/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2347 - acc: 0.9826 - val_loss: 11.9699 - val_acc: 0.9172\n","\n","Epoch 00355: acc did not improve from 0.98302\n","Epoch 356/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2842 - acc: 0.9825 - val_loss: 12.1412 - val_acc: 0.9105\n","\n","Epoch 00356: acc did not improve from 0.98302\n","Epoch 357/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3806 - acc: 0.9821 - val_loss: 11.7160 - val_acc: 0.9284\n","\n","Epoch 00357: acc did not improve from 0.98302\n","Epoch 358/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1327 - acc: 0.9827 - val_loss: 12.3312 - val_acc: 0.9253\n","\n","Epoch 00358: acc did not improve from 0.98302\n","Epoch 359/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1505 - acc: 0.9828 - val_loss: 13.2523 - val_acc: 0.9110\n","\n","Epoch 00359: acc did not improve from 0.98302\n","Epoch 360/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2870 - acc: 0.9783 - val_loss: 14.8829 - val_acc: 0.8914\n","\n","Epoch 00360: acc did not improve from 0.98302\n","Epoch 361/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5404 - acc: 0.9820 - val_loss: 11.3221 - val_acc: 0.9156\n","\n","Epoch 00361: acc did not improve from 0.98302\n","Epoch 362/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1992 - acc: 0.9828 - val_loss: 11.2690 - val_acc: 0.9307\n","\n","Epoch 00362: acc did not improve from 0.98302\n","Epoch 363/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1395 - acc: 0.9828 - val_loss: 11.8510 - val_acc: 0.9142\n","\n","Epoch 00363: acc did not improve from 0.98302\n","Epoch 364/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1622 - acc: 0.9827 - val_loss: 11.1518 - val_acc: 0.9347\n","\n","Epoch 00364: acc did not improve from 0.98302\n","Epoch 365/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1953 - acc: 0.9827 - val_loss: 11.7886 - val_acc: 0.9319\n","\n","Epoch 00365: acc did not improve from 0.98302\n","Epoch 366/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5072 - acc: 0.9813 - val_loss: 12.2473 - val_acc: 0.9186\n","\n","Epoch 00366: acc did not improve from 0.98302\n","Epoch 367/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1576 - acc: 0.9827 - val_loss: 11.9560 - val_acc: 0.9282\n","\n","Epoch 00367: acc did not improve from 0.98302\n","Epoch 368/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1628 - acc: 0.9828 - val_loss: 12.2869 - val_acc: 0.9174\n","\n","Epoch 00368: acc did not improve from 0.98302\n","Epoch 369/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3598 - acc: 0.9819 - val_loss: 14.2573 - val_acc: 0.8960\n","\n","Epoch 00369: acc did not improve from 0.98302\n","Epoch 370/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2489 - acc: 0.9826 - val_loss: 11.8283 - val_acc: 0.9371\n","\n","Epoch 00370: acc did not improve from 0.98302\n","Epoch 371/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1799 - acc: 0.9825 - val_loss: 13.7144 - val_acc: 0.9019\n","\n","Epoch 00371: acc did not improve from 0.98302\n","Epoch 372/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1662 - acc: 0.9827 - val_loss: 11.8777 - val_acc: 0.9117\n","\n","Epoch 00372: acc did not improve from 0.98302\n","Epoch 373/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1538 - acc: 0.9828 - val_loss: 14.0107 - val_acc: 0.9140\n","\n","Epoch 00373: acc did not improve from 0.98302\n","Epoch 374/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6815 - acc: 0.9814 - val_loss: 12.1509 - val_acc: 0.9325\n","\n","Epoch 00374: acc did not improve from 0.98302\n","Epoch 375/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2299 - acc: 0.9827 - val_loss: 11.9935 - val_acc: 0.9168\n","\n","Epoch 00375: acc did not improve from 0.98302\n","Epoch 376/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2059 - acc: 0.9827 - val_loss: 12.3194 - val_acc: 0.9248\n","\n","Epoch 00376: acc did not improve from 0.98302\n","Epoch 377/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1909 - acc: 0.9828 - val_loss: 11.9915 - val_acc: 0.9293\n","\n","Epoch 00377: acc did not improve from 0.98302\n","Epoch 378/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3634 - acc: 0.9820 - val_loss: 11.9906 - val_acc: 0.9293\n","\n","Epoch 00378: acc did not improve from 0.98302\n","Epoch 379/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1489 - acc: 0.9828 - val_loss: 11.5471 - val_acc: 0.9329\n","\n","Epoch 00379: acc did not improve from 0.98302\n","Epoch 380/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2460 - acc: 0.9826 - val_loss: 12.2956 - val_acc: 0.9182\n","\n","Epoch 00380: acc did not improve from 0.98302\n","Epoch 381/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3663 - acc: 0.9820 - val_loss: 12.2782 - val_acc: 0.9065\n","\n","Epoch 00381: acc did not improve from 0.98302\n","Epoch 382/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2827 - acc: 0.9823 - val_loss: 12.2381 - val_acc: 0.9145\n","\n","Epoch 00382: acc did not improve from 0.98302\n","Epoch 383/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1606 - acc: 0.9829 - val_loss: 11.6195 - val_acc: 0.9280\n","\n","Epoch 00383: acc did not improve from 0.98302\n","Epoch 384/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8371 - acc: 0.9804 - val_loss: 13.7949 - val_acc: 0.9086\n","\n","Epoch 00384: acc did not improve from 0.98302\n","Epoch 385/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2524 - acc: 0.9827 - val_loss: 11.8154 - val_acc: 0.9145\n","\n","Epoch 00385: acc did not improve from 0.98302\n","Epoch 386/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1782 - acc: 0.9829 - val_loss: 11.5160 - val_acc: 0.9367\n","\n","Epoch 00386: acc did not improve from 0.98302\n","Epoch 387/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2127 - acc: 0.9826 - val_loss: 11.0551 - val_acc: 0.9254\n","\n","Epoch 00387: acc did not improve from 0.98302\n","Epoch 388/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2535 - acc: 0.9825 - val_loss: 12.2831 - val_acc: 0.9267\n","\n","Epoch 00388: acc did not improve from 0.98302\n","Epoch 389/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1814 - acc: 0.9827 - val_loss: 11.5976 - val_acc: 0.9146\n","\n","Epoch 00389: acc did not improve from 0.98302\n","Epoch 390/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1645 - acc: 0.9828 - val_loss: 11.5759 - val_acc: 0.9101\n","\n","Epoch 00390: acc did not improve from 0.98302\n","Epoch 391/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2217 - acc: 0.9827 - val_loss: 12.6276 - val_acc: 0.9096\n","\n","Epoch 00391: acc did not improve from 0.98302\n","Epoch 392/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1659 - acc: 0.9828 - val_loss: 11.3935 - val_acc: 0.9376\n","\n","Epoch 00392: acc did not improve from 0.98302\n","Epoch 393/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2606 - acc: 0.9825 - val_loss: 11.5986 - val_acc: 0.9348\n","\n","Epoch 00393: acc did not improve from 0.98302\n","Epoch 394/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2731 - acc: 0.9826 - val_loss: 12.5294 - val_acc: 0.9317\n","\n","Epoch 00394: acc did not improve from 0.98302\n","Epoch 395/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2255 - acc: 0.9827 - val_loss: 11.3520 - val_acc: 0.9180\n","\n","Epoch 00395: acc did not improve from 0.98302\n","Epoch 396/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1501 - acc: 0.9830 - val_loss: 11.5441 - val_acc: 0.9391\n","\n","Epoch 00396: acc did not improve from 0.98302\n","Epoch 397/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2320 - acc: 0.9825 - val_loss: 11.6394 - val_acc: 0.9306\n","\n","Epoch 00397: acc did not improve from 0.98302\n","Epoch 398/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4102 - acc: 0.9819 - val_loss: 12.4116 - val_acc: 0.9084\n","\n","Epoch 00398: acc did not improve from 0.98302\n","Epoch 399/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1651 - acc: 0.9826 - val_loss: 12.0944 - val_acc: 0.9238\n","\n","Epoch 00399: acc did not improve from 0.98302\n","Epoch 400/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1597 - acc: 0.9829 - val_loss: 13.2344 - val_acc: 0.9159\n","\n","Epoch 00400: acc did not improve from 0.98302\n","Epoch 401/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1288 - acc: 0.9831 - val_loss: 13.2796 - val_acc: 0.9150\n","\n","Epoch 00401: acc improved from 0.98302 to 0.98307, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/401_0.98307.hdf5\n","Epoch 402/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3693 - acc: 0.9822 - val_loss: 14.9070 - val_acc: 0.9061\n","\n","Epoch 00402: acc did not improve from 0.98307\n","Epoch 403/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1088 - acc: 0.9798 - val_loss: 12.5770 - val_acc: 0.9253\n","\n","Epoch 00403: acc did not improve from 0.98307\n","Epoch 404/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2987 - acc: 0.9827 - val_loss: 13.5659 - val_acc: 0.9095\n","\n","Epoch 00404: acc did not improve from 0.98307\n","Epoch 405/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1077 - acc: 0.9832 - val_loss: 12.1947 - val_acc: 0.9165\n","\n","Epoch 00405: acc improved from 0.98307 to 0.98320, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/405_0.98320.hdf5\n","Epoch 406/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1157 - acc: 0.9830 - val_loss: 12.1889 - val_acc: 0.9341\n","\n","Epoch 00406: acc did not improve from 0.98320\n","Epoch 407/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1707 - acc: 0.9827 - val_loss: 12.1179 - val_acc: 0.9296\n","\n","Epoch 00407: acc did not improve from 0.98320\n","Epoch 408/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2267 - acc: 0.9829 - val_loss: 12.1955 - val_acc: 0.9251\n","\n","Epoch 00408: acc did not improve from 0.98320\n","Epoch 409/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1990 - acc: 0.9828 - val_loss: 11.7872 - val_acc: 0.9183\n","\n","Epoch 00409: acc did not improve from 0.98320\n","Epoch 410/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1753 - acc: 0.9828 - val_loss: 11.7455 - val_acc: 0.9296\n","\n","Epoch 00410: acc did not improve from 0.98320\n","Epoch 411/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1711 - acc: 0.9829 - val_loss: 12.4366 - val_acc: 0.9208\n","\n","Epoch 00411: acc did not improve from 0.98320\n","Epoch 412/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3774 - acc: 0.9819 - val_loss: 11.4670 - val_acc: 0.9119\n","\n","Epoch 00412: acc did not improve from 0.98320\n","Epoch 413/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2808 - acc: 0.9823 - val_loss: 14.6358 - val_acc: 0.9011\n","\n","Epoch 00413: acc did not improve from 0.98320\n","Epoch 414/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8838 - acc: 0.9803 - val_loss: 12.1321 - val_acc: 0.9273\n","\n","Epoch 00414: acc did not improve from 0.98320\n","Epoch 415/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1355 - acc: 0.9828 - val_loss: 12.3960 - val_acc: 0.9256\n","\n","Epoch 00415: acc did not improve from 0.98320\n","Epoch 416/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1114 - acc: 0.9830 - val_loss: 12.2697 - val_acc: 0.9167\n","\n","Epoch 00416: acc did not improve from 0.98320\n","Epoch 417/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1101 - acc: 0.9828 - val_loss: 11.4804 - val_acc: 0.9309\n","\n","Epoch 00417: acc did not improve from 0.98320\n","Epoch 418/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1762 - acc: 0.9827 - val_loss: 12.8650 - val_acc: 0.9037\n","\n","Epoch 00418: acc did not improve from 0.98320\n","Epoch 419/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2188 - acc: 0.9826 - val_loss: 12.3567 - val_acc: 0.9185\n","\n","Epoch 00419: acc did not improve from 0.98320\n","Epoch 420/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2027 - acc: 0.9825 - val_loss: 11.6032 - val_acc: 0.9355\n","\n","Epoch 00420: acc did not improve from 0.98320\n","Epoch 421/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1741 - acc: 0.9825 - val_loss: 11.6123 - val_acc: 0.9257\n","\n","Epoch 00421: acc did not improve from 0.98320\n","Epoch 422/1000\n","769500/769500 [==============================] - 10s 12us/step - loss: 1.1995 - acc: 0.9827 - val_loss: 12.1044 - val_acc: 0.9353\n","\n","Epoch 00422: acc did not improve from 0.98320\n","Epoch 423/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1420 - acc: 0.9827 - val_loss: 12.4894 - val_acc: 0.9122\n","\n","Epoch 00423: acc did not improve from 0.98320\n","Epoch 424/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2520 - acc: 0.9826 - val_loss: 12.6447 - val_acc: 0.9159\n","\n","Epoch 00424: acc did not improve from 0.98320\n","Epoch 425/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3082 - acc: 0.9823 - val_loss: 12.4481 - val_acc: 0.9185\n","\n","Epoch 00425: acc did not improve from 0.98320\n","Epoch 426/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1457 - acc: 0.9828 - val_loss: 10.7314 - val_acc: 0.9246\n","\n","Epoch 00426: acc did not improve from 0.98320\n","Epoch 427/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2572 - acc: 0.9825 - val_loss: 12.3694 - val_acc: 0.9132\n","\n","Epoch 00427: acc did not improve from 0.98320\n","Epoch 428/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1961 - acc: 0.9825 - val_loss: 12.6611 - val_acc: 0.9214\n","\n","Epoch 00428: acc did not improve from 0.98320\n","Epoch 429/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3029 - acc: 0.9820 - val_loss: 11.6306 - val_acc: 0.9315\n","\n","Epoch 00429: acc did not improve from 0.98320\n","Epoch 430/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1472 - acc: 0.9828 - val_loss: 13.8505 - val_acc: 0.8941\n","\n","Epoch 00430: acc did not improve from 0.98320\n","Epoch 431/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2276 - acc: 0.9825 - val_loss: 12.0409 - val_acc: 0.9137\n","\n","Epoch 00431: acc did not improve from 0.98320\n","Epoch 432/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1803 - acc: 0.9826 - val_loss: 11.8782 - val_acc: 0.9302\n","\n","Epoch 00432: acc did not improve from 0.98320\n","Epoch 433/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1543 - acc: 0.9827 - val_loss: 11.3247 - val_acc: 0.9247\n","\n","Epoch 00433: acc did not improve from 0.98320\n","Epoch 434/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2923 - acc: 0.9824 - val_loss: 12.4339 - val_acc: 0.9172\n","\n","Epoch 00434: acc did not improve from 0.98320\n","Epoch 435/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1821 - acc: 0.9826 - val_loss: 12.4217 - val_acc: 0.9205\n","\n","Epoch 00435: acc did not improve from 0.98320\n","Epoch 436/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2491 - acc: 0.9825 - val_loss: 12.0803 - val_acc: 0.9206\n","\n","Epoch 00436: acc did not improve from 0.98320\n","Epoch 437/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2225 - acc: 0.9824 - val_loss: 12.5238 - val_acc: 0.9178\n","\n","Epoch 00437: acc did not improve from 0.98320\n","Epoch 438/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1458 - acc: 0.9826 - val_loss: 11.9528 - val_acc: 0.9228\n","\n","Epoch 00438: acc did not improve from 0.98320\n","Epoch 439/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2155 - acc: 0.9826 - val_loss: 11.8009 - val_acc: 0.9244\n","\n","Epoch 00439: acc did not improve from 0.98320\n","Epoch 440/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0813 - acc: 0.9829 - val_loss: 11.9442 - val_acc: 0.9243\n","\n","Epoch 00440: acc did not improve from 0.98320\n","Epoch 441/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1878 - acc: 0.9827 - val_loss: 13.0044 - val_acc: 0.9232\n","\n","Epoch 00441: acc did not improve from 0.98320\n","Epoch 442/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5119 - acc: 0.9815 - val_loss: 12.4126 - val_acc: 0.9145\n","\n","Epoch 00442: acc did not improve from 0.98320\n","Epoch 443/1000\n","769500/769500 [==============================] - 10s 12us/step - loss: 1.1544 - acc: 0.9828 - val_loss: 13.3116 - val_acc: 0.9079\n","\n","Epoch 00443: acc did not improve from 0.98320\n","Epoch 444/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1320 - acc: 0.9827 - val_loss: 12.1006 - val_acc: 0.9159\n","\n","Epoch 00444: acc did not improve from 0.98320\n","Epoch 445/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2489 - acc: 0.9823 - val_loss: 11.7371 - val_acc: 0.9155\n","\n","Epoch 00445: acc did not improve from 0.98320\n","Epoch 446/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2083 - acc: 0.9827 - val_loss: 15.4231 - val_acc: 0.8953\n","\n","Epoch 00446: acc did not improve from 0.98320\n","Epoch 447/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4858 - acc: 0.9819 - val_loss: 11.8702 - val_acc: 0.9323\n","\n","Epoch 00447: acc did not improve from 0.98320\n","Epoch 448/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1454 - acc: 0.9828 - val_loss: 12.5509 - val_acc: 0.9301\n","\n","Epoch 00448: acc did not improve from 0.98320\n","Epoch 449/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1860 - acc: 0.9825 - val_loss: 12.0702 - val_acc: 0.9194\n","\n","Epoch 00449: acc did not improve from 0.98320\n","Epoch 450/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1511 - acc: 0.9828 - val_loss: 11.3911 - val_acc: 0.9301\n","\n","Epoch 00450: acc did not improve from 0.98320\n","Epoch 451/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4498 - acc: 0.9818 - val_loss: 13.5725 - val_acc: 0.9087\n","\n","Epoch 00451: acc did not improve from 0.98320\n","Epoch 452/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3317 - acc: 0.9822 - val_loss: 11.8653 - val_acc: 0.9170\n","\n","Epoch 00452: acc did not improve from 0.98320\n","Epoch 453/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0668 - acc: 0.9829 - val_loss: 11.9133 - val_acc: 0.9237\n","\n","Epoch 00453: acc did not improve from 0.98320\n","Epoch 454/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0958 - acc: 0.9827 - val_loss: 11.8889 - val_acc: 0.9428\n","\n","Epoch 00454: acc did not improve from 0.98320\n","Epoch 455/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2466 - acc: 0.9824 - val_loss: 12.8320 - val_acc: 0.9235\n","\n","Epoch 00455: acc did not improve from 0.98320\n","Epoch 456/1000\n","769500/769500 [==============================] - 10s 13us/step - loss: 1.2033 - acc: 0.9824 - val_loss: 11.8725 - val_acc: 0.9177\n","\n","Epoch 00456: acc did not improve from 0.98320\n","Epoch 457/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1098 - acc: 0.9828 - val_loss: 12.8804 - val_acc: 0.9046\n","\n","Epoch 00457: acc did not improve from 0.98320\n","Epoch 458/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1625 - acc: 0.9827 - val_loss: 12.1358 - val_acc: 0.9401\n","\n","Epoch 00458: acc did not improve from 0.98320\n","Epoch 459/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3506 - acc: 0.9822 - val_loss: 12.3235 - val_acc: 0.9125\n","\n","Epoch 00459: acc did not improve from 0.98320\n","Epoch 460/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1821 - acc: 0.9826 - val_loss: 12.0729 - val_acc: 0.9293\n","\n","Epoch 00460: acc did not improve from 0.98320\n","Epoch 461/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1377 - acc: 0.9827 - val_loss: 12.1309 - val_acc: 0.9281\n","\n","Epoch 00461: acc did not improve from 0.98320\n","Epoch 462/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1102 - acc: 0.9828 - val_loss: 12.0718 - val_acc: 0.9218\n","\n","Epoch 00462: acc did not improve from 0.98320\n","Epoch 463/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0971 - acc: 0.9827 - val_loss: 12.3313 - val_acc: 0.9115\n","\n","Epoch 00463: acc did not improve from 0.98320\n","Epoch 464/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3346 - acc: 0.9821 - val_loss: 12.9930 - val_acc: 0.9014\n","\n","Epoch 00464: acc did not improve from 0.98320\n","Epoch 465/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1398 - acc: 0.9827 - val_loss: 12.9093 - val_acc: 0.9126\n","\n","Epoch 00465: acc did not improve from 0.98320\n","Epoch 466/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2202 - acc: 0.9825 - val_loss: 12.5690 - val_acc: 0.9106\n","\n","Epoch 00466: acc did not improve from 0.98320\n","Epoch 467/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4034 - acc: 0.9817 - val_loss: 13.4220 - val_acc: 0.9216\n","\n","Epoch 00467: acc did not improve from 0.98320\n","Epoch 468/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1947 - acc: 0.9827 - val_loss: 12.4313 - val_acc: 0.9264\n","\n","Epoch 00468: acc did not improve from 0.98320\n","Epoch 469/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0521 - acc: 0.9829 - val_loss: 11.4399 - val_acc: 0.9212\n","\n","Epoch 00469: acc did not improve from 0.98320\n","Epoch 470/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1040 - acc: 0.9826 - val_loss: 12.3058 - val_acc: 0.9321\n","\n","Epoch 00470: acc did not improve from 0.98320\n","Epoch 471/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2801 - acc: 0.9822 - val_loss: 11.2715 - val_acc: 0.9219\n","\n","Epoch 00471: acc did not improve from 0.98320\n","Epoch 472/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3273 - acc: 0.9822 - val_loss: 11.6228 - val_acc: 0.9214\n","\n","Epoch 00472: acc did not improve from 0.98320\n","Epoch 473/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1891 - acc: 0.9827 - val_loss: 12.0294 - val_acc: 0.9107\n","\n","Epoch 00473: acc did not improve from 0.98320\n","Epoch 474/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2643 - acc: 0.9822 - val_loss: 11.3202 - val_acc: 0.9295\n","\n","Epoch 00474: acc did not improve from 0.98320\n","Epoch 475/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0887 - acc: 0.9829 - val_loss: 12.2740 - val_acc: 0.9149\n","\n","Epoch 00475: acc did not improve from 0.98320\n","Epoch 476/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2202 - acc: 0.9823 - val_loss: 13.0788 - val_acc: 0.9191\n","\n","Epoch 00476: acc did not improve from 0.98320\n","Epoch 477/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2525 - acc: 0.9823 - val_loss: 12.8420 - val_acc: 0.9057\n","\n","Epoch 00477: acc did not improve from 0.98320\n","Epoch 478/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1475 - acc: 0.9827 - val_loss: 13.1383 - val_acc: 0.9161\n","\n","Epoch 00478: acc did not improve from 0.98320\n","Epoch 479/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0811 - acc: 0.9827 - val_loss: 12.2245 - val_acc: 0.9187\n","\n","Epoch 00479: acc did not improve from 0.98320\n","Epoch 480/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2130 - acc: 0.9826 - val_loss: 12.0890 - val_acc: 0.9190\n","\n","Epoch 00480: acc did not improve from 0.98320\n","Epoch 481/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2053 - acc: 0.9828 - val_loss: 12.5447 - val_acc: 0.9208\n","\n","Epoch 00481: acc did not improve from 0.98320\n","Epoch 482/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1014 - acc: 0.9827 - val_loss: 12.4216 - val_acc: 0.9252\n","\n","Epoch 00482: acc did not improve from 0.98320\n","Epoch 483/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1694 - acc: 0.9826 - val_loss: 11.1484 - val_acc: 0.9298\n","\n","Epoch 00483: acc did not improve from 0.98320\n","Epoch 484/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1693 - acc: 0.9826 - val_loss: 12.2637 - val_acc: 0.9263\n","\n","Epoch 00484: acc did not improve from 0.98320\n","Epoch 485/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2912 - acc: 0.9826 - val_loss: 12.6895 - val_acc: 0.9167\n","\n","Epoch 00485: acc did not improve from 0.98320\n","Epoch 486/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1159 - acc: 0.9827 - val_loss: 11.8506 - val_acc: 0.9353\n","\n","Epoch 00486: acc did not improve from 0.98320\n","Epoch 487/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3063 - acc: 0.9823 - val_loss: 12.1290 - val_acc: 0.9205\n","\n","Epoch 00487: acc did not improve from 0.98320\n","Epoch 488/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1917 - acc: 0.9826 - val_loss: 11.3586 - val_acc: 0.9328\n","\n","Epoch 00488: acc did not improve from 0.98320\n","Epoch 489/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1640 - acc: 0.9825 - val_loss: 12.4548 - val_acc: 0.9078\n","\n","Epoch 00489: acc did not improve from 0.98320\n","Epoch 490/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1588 - acc: 0.9825 - val_loss: 13.4361 - val_acc: 0.9146\n","\n","Epoch 00490: acc did not improve from 0.98320\n","Epoch 491/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.6121 - acc: 0.9771 - val_loss: 12.5120 - val_acc: 0.9171\n","\n","Epoch 00491: acc did not improve from 0.98320\n","Epoch 492/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2843 - acc: 0.9826 - val_loss: 12.9834 - val_acc: 0.9279\n","\n","Epoch 00492: acc did not improve from 0.98320\n","Epoch 493/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0709 - acc: 0.9829 - val_loss: 13.5339 - val_acc: 0.9065\n","\n","Epoch 00493: acc did not improve from 0.98320\n","Epoch 494/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.0020 - acc: 0.9829 - val_loss: 11.6410 - val_acc: 0.9300\n","\n","Epoch 00494: acc did not improve from 0.98320\n","Epoch 495/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3266 - acc: 0.9819 - val_loss: 13.2026 - val_acc: 0.9083\n","\n","Epoch 00495: acc did not improve from 0.98320\n","Epoch 496/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1255 - acc: 0.9828 - val_loss: 11.9141 - val_acc: 0.9205\n","\n","Epoch 00496: acc did not improve from 0.98320\n","Epoch 497/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1601 - acc: 0.9825 - val_loss: 11.8617 - val_acc: 0.9158\n","\n","Epoch 00497: acc did not improve from 0.98320\n","Epoch 498/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.1271 - acc: 0.9826 - val_loss: 12.7563 - val_acc: 0.9254\n","\n","Epoch 00498: acc did not improve from 0.98320\n","Epoch 499/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2543 - acc: 0.9823 - val_loss: 13.3602 - val_acc: 0.9064\n","\n","Epoch 00499: acc did not improve from 0.98320\n","Epoch 500/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5126 - acc: 0.9819 - val_loss: 12.6723 - val_acc: 0.9166\n","\n","Epoch 00500: acc did not improve from 0.98320\n","Epoch 501/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0124 - acc: 0.9799 - val_loss: 12.5995 - val_acc: 0.9270\n","\n","Epoch 00501: acc did not improve from 0.98320\n","Epoch 502/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5302 - acc: 0.9819 - val_loss: 13.1165 - val_acc: 0.9103\n","\n","Epoch 00502: acc did not improve from 0.98320\n","Epoch 503/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6217 - acc: 0.9817 - val_loss: 12.9736 - val_acc: 0.9176\n","\n","Epoch 00503: acc did not improve from 0.98320\n","Epoch 504/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7959 - acc: 0.9804 - val_loss: 26.0500 - val_acc: 0.8679\n","\n","Epoch 00504: acc did not improve from 0.98320\n","Epoch 505/1000\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8948 - acc: 0.9807 - val_loss: 13.5862 - val_acc: 0.9066\n","\n","Epoch 00505: acc did not improve from 0.98320\n","Epoch 506/1000\n","310000/769500 [===========>..................] - ETA: 5s - loss: 1.2349 - acc: 0.9826"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-8a71fff25d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_train_n4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"B6Dm83Trg2Yg"},"source":["from keras.models import load_model\n","\n","model = load_model(work_dir + '405_0.98320.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sblqGUVGwgz0","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1580321863137,"user_tz":-540,"elapsed":89329,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}},"outputId":"b2a514a7-99af-4448-8bf2-672c344eb497"},"source":["# loss \n","\n","loss = model.evaluate(fea_train , tar_train_n4, batch_size = 32)\n","print('loss: ', str(loss))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["810000/810000 [==============================] - 89s 110us/step\n","loss:  [1.6445477069878285, 0.977179012345679]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ugnp1NPAwg0X"},"source":["fea_test = test.iloc[:,1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-NdM1ARwg0b"},"source":["pred_test_1 = model.predict(fea_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiWNt8I-qTNJ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1580324634864,"user_tz":-540,"elapsed":2757704,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}},"outputId":"e9f8044f-77b9-4852-c1dc-8f576b0adb03"},"source":["# 산화규소 층\n","\n","model.compile(loss='mae', optimizer='adam', metrics=['acc']) \n","model.fit(fea_train, tar_train_o2, epochs=500, batch_size=1000,callbacks=[cb_checkpoint], validation_split = 0.05)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 769500 samples, validate on 40500 samples\n","Epoch 1/500\n","769500/769500 [==============================] - 18s 23us/step - loss: 24.3043 - acc: 0.8496 - val_loss: 18.3846 - val_acc: 0.8961\n","\n","Epoch 00001: acc did not improve from 0.98320\n","Epoch 2/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 7.3520 - acc: 0.9566 - val_loss: 16.6657 - val_acc: 0.9123\n","\n","Epoch 00002: acc did not improve from 0.98320\n","Epoch 3/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 5.5635 - acc: 0.9670 - val_loss: 14.4400 - val_acc: 0.9225\n","\n","Epoch 00003: acc did not improve from 0.98320\n","Epoch 4/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 4.6703 - acc: 0.9716 - val_loss: 12.4403 - val_acc: 0.9319\n","\n","Epoch 00004: acc did not improve from 0.98320\n","Epoch 5/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 4.3625 - acc: 0.9734 - val_loss: 12.0369 - val_acc: 0.9356\n","\n","Epoch 00005: acc did not improve from 0.98320\n","Epoch 6/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.9106 - acc: 0.9752 - val_loss: 11.9601 - val_acc: 0.9319\n","\n","Epoch 00006: acc did not improve from 0.98320\n","Epoch 7/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.5621 - acc: 0.9770 - val_loss: 11.0773 - val_acc: 0.9402\n","\n","Epoch 00007: acc did not improve from 0.98320\n","Epoch 8/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.3645 - acc: 0.9777 - val_loss: 10.7157 - val_acc: 0.9413\n","\n","Epoch 00008: acc did not improve from 0.98320\n","Epoch 9/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.2798 - acc: 0.9777 - val_loss: 11.0712 - val_acc: 0.9404\n","\n","Epoch 00009: acc did not improve from 0.98320\n","Epoch 10/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.0925 - acc: 0.9789 - val_loss: 9.8716 - val_acc: 0.9483\n","\n","Epoch 00010: acc did not improve from 0.98320\n","Epoch 11/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 3.0046 - acc: 0.9793 - val_loss: 9.7018 - val_acc: 0.9471\n","\n","Epoch 00011: acc did not improve from 0.98320\n","Epoch 12/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.9703 - acc: 0.9790 - val_loss: 10.3980 - val_acc: 0.9450\n","\n","Epoch 00012: acc did not improve from 0.98320\n","Epoch 13/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.8330 - acc: 0.9798 - val_loss: 10.0730 - val_acc: 0.9466\n","\n","Epoch 00013: acc did not improve from 0.98320\n","Epoch 14/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.7501 - acc: 0.9801 - val_loss: 9.3099 - val_acc: 0.9534\n","\n","Epoch 00014: acc did not improve from 0.98320\n","Epoch 15/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.6671 - acc: 0.9804 - val_loss: 9.9951 - val_acc: 0.9485\n","\n","Epoch 00015: acc did not improve from 0.98320\n","Epoch 16/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.5750 - acc: 0.9808 - val_loss: 9.5181 - val_acc: 0.9521\n","\n","Epoch 00016: acc did not improve from 0.98320\n","Epoch 17/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.4858 - acc: 0.9810 - val_loss: 9.6269 - val_acc: 0.9502\n","\n","Epoch 00017: acc did not improve from 0.98320\n","Epoch 18/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.5062 - acc: 0.9807 - val_loss: 9.1413 - val_acc: 0.9512\n","\n","Epoch 00018: acc did not improve from 0.98320\n","Epoch 19/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.5463 - acc: 0.9806 - val_loss: 9.1655 - val_acc: 0.9490\n","\n","Epoch 00019: acc did not improve from 0.98320\n","Epoch 20/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.4324 - acc: 0.9809 - val_loss: 9.1240 - val_acc: 0.9537\n","\n","Epoch 00020: acc did not improve from 0.98320\n","Epoch 21/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.3252 - acc: 0.9813 - val_loss: 8.5841 - val_acc: 0.9535\n","\n","Epoch 00021: acc did not improve from 0.98320\n","Epoch 22/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.3170 - acc: 0.9813 - val_loss: 9.0355 - val_acc: 0.9536\n","\n","Epoch 00022: acc did not improve from 0.98320\n","Epoch 23/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.3010 - acc: 0.9812 - val_loss: 9.1634 - val_acc: 0.9560\n","\n","Epoch 00023: acc did not improve from 0.98320\n","Epoch 24/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2744 - acc: 0.9815 - val_loss: 8.7053 - val_acc: 0.9554\n","\n","Epoch 00024: acc did not improve from 0.98320\n","Epoch 25/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2484 - acc: 0.9814 - val_loss: 8.9682 - val_acc: 0.9506\n","\n","Epoch 00025: acc did not improve from 0.98320\n","Epoch 26/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.3000 - acc: 0.9812 - val_loss: 8.5085 - val_acc: 0.9555\n","\n","Epoch 00026: acc did not improve from 0.98320\n","Epoch 27/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2625 - acc: 0.9813 - val_loss: 8.4271 - val_acc: 0.9552\n","\n","Epoch 00027: acc did not improve from 0.98320\n","Epoch 28/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1726 - acc: 0.9814 - val_loss: 8.5056 - val_acc: 0.9549\n","\n","Epoch 00028: acc did not improve from 0.98320\n","Epoch 29/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1528 - acc: 0.9816 - val_loss: 8.6111 - val_acc: 0.9565\n","\n","Epoch 00029: acc did not improve from 0.98320\n","Epoch 30/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1811 - acc: 0.9814 - val_loss: 8.4059 - val_acc: 0.9553\n","\n","Epoch 00030: acc did not improve from 0.98320\n","Epoch 31/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2342 - acc: 0.9813 - val_loss: 8.4402 - val_acc: 0.9572\n","\n","Epoch 00031: acc did not improve from 0.98320\n","Epoch 32/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0157 - acc: 0.9821 - val_loss: 8.1917 - val_acc: 0.9575\n","\n","Epoch 00032: acc did not improve from 0.98320\n","Epoch 33/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0833 - acc: 0.9817 - val_loss: 8.2290 - val_acc: 0.9562\n","\n","Epoch 00033: acc did not improve from 0.98320\n","Epoch 34/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2193 - acc: 0.9812 - val_loss: 8.3812 - val_acc: 0.9567\n","\n","Epoch 00034: acc did not improve from 0.98320\n","Epoch 35/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9794 - acc: 0.9820 - val_loss: 8.2623 - val_acc: 0.9562\n","\n","Epoch 00035: acc did not improve from 0.98320\n","Epoch 36/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0723 - acc: 0.9818 - val_loss: 7.9609 - val_acc: 0.9575\n","\n","Epoch 00036: acc did not improve from 0.98320\n","Epoch 37/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9937 - acc: 0.9820 - val_loss: 8.9096 - val_acc: 0.9546\n","\n","Epoch 00037: acc did not improve from 0.98320\n","Epoch 38/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9691 - acc: 0.9822 - val_loss: 8.3433 - val_acc: 0.9569\n","\n","Epoch 00038: acc did not improve from 0.98320\n","Epoch 39/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9959 - acc: 0.9818 - val_loss: 8.5831 - val_acc: 0.9563\n","\n","Epoch 00039: acc did not improve from 0.98320\n","Epoch 40/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9534 - acc: 0.9821 - val_loss: 7.7010 - val_acc: 0.9593\n","\n","Epoch 00040: acc did not improve from 0.98320\n","Epoch 41/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9422 - acc: 0.9821 - val_loss: 8.3513 - val_acc: 0.9610\n","\n","Epoch 00041: acc did not improve from 0.98320\n","Epoch 42/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9398 - acc: 0.9820 - val_loss: 7.7182 - val_acc: 0.9615\n","\n","Epoch 00042: acc did not improve from 0.98320\n","Epoch 43/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8679 - acc: 0.9823 - val_loss: 7.8092 - val_acc: 0.9590\n","\n","Epoch 00043: acc did not improve from 0.98320\n","Epoch 44/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9031 - acc: 0.9822 - val_loss: 7.9146 - val_acc: 0.9594\n","\n","Epoch 00044: acc did not improve from 0.98320\n","Epoch 45/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9408 - acc: 0.9819 - val_loss: 8.2288 - val_acc: 0.9571\n","\n","Epoch 00045: acc did not improve from 0.98320\n","Epoch 46/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9340 - acc: 0.9819 - val_loss: 7.6800 - val_acc: 0.9580\n","\n","Epoch 00046: acc did not improve from 0.98320\n","Epoch 47/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9088 - acc: 0.9821 - val_loss: 8.1055 - val_acc: 0.9601\n","\n","Epoch 00047: acc did not improve from 0.98320\n","Epoch 48/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8115 - acc: 0.9823 - val_loss: 7.4857 - val_acc: 0.9608\n","\n","Epoch 00048: acc did not improve from 0.98320\n","Epoch 49/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8494 - acc: 0.9821 - val_loss: 7.7245 - val_acc: 0.9595\n","\n","Epoch 00049: acc did not improve from 0.98320\n","Epoch 50/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0472 - acc: 0.9813 - val_loss: 7.7264 - val_acc: 0.9596\n","\n","Epoch 00050: acc did not improve from 0.98320\n","Epoch 51/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9081 - acc: 0.9819 - val_loss: 8.3863 - val_acc: 0.9569\n","\n","Epoch 00051: acc did not improve from 0.98320\n","Epoch 52/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7680 - acc: 0.9824 - val_loss: 7.6687 - val_acc: 0.9594\n","\n","Epoch 00052: acc did not improve from 0.98320\n","Epoch 53/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7931 - acc: 0.9821 - val_loss: 7.9109 - val_acc: 0.9612\n","\n","Epoch 00053: acc did not improve from 0.98320\n","Epoch 54/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7622 - acc: 0.9824 - val_loss: 7.6898 - val_acc: 0.9617\n","\n","Epoch 00054: acc did not improve from 0.98320\n","Epoch 55/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8432 - acc: 0.9821 - val_loss: 7.4274 - val_acc: 0.9616\n","\n","Epoch 00055: acc did not improve from 0.98320\n","Epoch 56/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7097 - acc: 0.9825 - val_loss: 8.3493 - val_acc: 0.9582\n","\n","Epoch 00056: acc did not improve from 0.98320\n","Epoch 57/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8820 - acc: 0.9818 - val_loss: 8.3007 - val_acc: 0.9535\n","\n","Epoch 00057: acc did not improve from 0.98320\n","Epoch 58/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8286 - acc: 0.9821 - val_loss: 7.7513 - val_acc: 0.9620\n","\n","Epoch 00058: acc did not improve from 0.98320\n","Epoch 59/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9171 - acc: 0.9817 - val_loss: 7.5180 - val_acc: 0.9606\n","\n","Epoch 00059: acc did not improve from 0.98320\n","Epoch 60/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6832 - acc: 0.9826 - val_loss: 7.5609 - val_acc: 0.9626\n","\n","Epoch 00060: acc did not improve from 0.98320\n","Epoch 61/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6868 - acc: 0.9826 - val_loss: 7.5020 - val_acc: 0.9595\n","\n","Epoch 00061: acc did not improve from 0.98320\n","Epoch 62/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7696 - acc: 0.9821 - val_loss: 7.6817 - val_acc: 0.9567\n","\n","Epoch 00062: acc did not improve from 0.98320\n","Epoch 63/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9629 - acc: 0.9814 - val_loss: 7.2471 - val_acc: 0.9602\n","\n","Epoch 00063: acc did not improve from 0.98320\n","Epoch 64/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7502 - acc: 0.9824 - val_loss: 7.5284 - val_acc: 0.9615\n","\n","Epoch 00064: acc did not improve from 0.98320\n","Epoch 65/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7078 - acc: 0.9823 - val_loss: 7.3963 - val_acc: 0.9611\n","\n","Epoch 00065: acc did not improve from 0.98320\n","Epoch 66/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9699 - acc: 0.9815 - val_loss: 7.8732 - val_acc: 0.9584\n","\n","Epoch 00066: acc did not improve from 0.98320\n","Epoch 67/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6939 - acc: 0.9825 - val_loss: 7.2300 - val_acc: 0.9615\n","\n","Epoch 00067: acc did not improve from 0.98320\n","Epoch 68/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6542 - acc: 0.9826 - val_loss: 7.8857 - val_acc: 0.9608\n","\n","Epoch 00068: acc did not improve from 0.98320\n","Epoch 69/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6596 - acc: 0.9826 - val_loss: 7.4305 - val_acc: 0.9599\n","\n","Epoch 00069: acc did not improve from 0.98320\n","Epoch 70/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6973 - acc: 0.9827 - val_loss: 7.4874 - val_acc: 0.9588\n","\n","Epoch 00070: acc did not improve from 0.98320\n","Epoch 71/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6514 - acc: 0.9827 - val_loss: 7.2960 - val_acc: 0.9627\n","\n","Epoch 00071: acc did not improve from 0.98320\n","Epoch 72/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6544 - acc: 0.9826 - val_loss: 7.0911 - val_acc: 0.9612\n","\n","Epoch 00072: acc did not improve from 0.98320\n","Epoch 73/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6881 - acc: 0.9827 - val_loss: 7.2635 - val_acc: 0.9617\n","\n","Epoch 00073: acc did not improve from 0.98320\n","Epoch 74/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6793 - acc: 0.9823 - val_loss: 7.2994 - val_acc: 0.9609\n","\n","Epoch 00074: acc did not improve from 0.98320\n","Epoch 75/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7285 - acc: 0.9823 - val_loss: 7.7288 - val_acc: 0.9593\n","\n","Epoch 00075: acc did not improve from 0.98320\n","Epoch 76/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7633 - acc: 0.9822 - val_loss: 7.3423 - val_acc: 0.9622\n","\n","Epoch 00076: acc did not improve from 0.98320\n","Epoch 77/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6576 - acc: 0.9826 - val_loss: 7.1571 - val_acc: 0.9617\n","\n","Epoch 00077: acc did not improve from 0.98320\n","Epoch 78/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6797 - acc: 0.9826 - val_loss: 7.2486 - val_acc: 0.9624\n","\n","Epoch 00078: acc did not improve from 0.98320\n","Epoch 79/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6106 - acc: 0.9827 - val_loss: 7.5738 - val_acc: 0.9600\n","\n","Epoch 00079: acc did not improve from 0.98320\n","Epoch 80/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6624 - acc: 0.9824 - val_loss: 7.3946 - val_acc: 0.9623\n","\n","Epoch 00080: acc did not improve from 0.98320\n","Epoch 81/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8546 - acc: 0.9821 - val_loss: 7.2625 - val_acc: 0.9624\n","\n","Epoch 00081: acc did not improve from 0.98320\n","Epoch 82/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6124 - acc: 0.9828 - val_loss: 7.2740 - val_acc: 0.9617\n","\n","Epoch 00082: acc did not improve from 0.98320\n","Epoch 83/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6387 - acc: 0.9825 - val_loss: 7.2356 - val_acc: 0.9621\n","\n","Epoch 00083: acc did not improve from 0.98320\n","Epoch 84/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7179 - acc: 0.9820 - val_loss: 7.2108 - val_acc: 0.9632\n","\n","Epoch 00084: acc did not improve from 0.98320\n","Epoch 85/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8872 - acc: 0.9818 - val_loss: 6.9926 - val_acc: 0.9608\n","\n","Epoch 00085: acc did not improve from 0.98320\n","Epoch 86/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6144 - acc: 0.9827 - val_loss: 7.3903 - val_acc: 0.9624\n","\n","Epoch 00086: acc did not improve from 0.98320\n","Epoch 87/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5274 - acc: 0.9828 - val_loss: 6.9821 - val_acc: 0.9640\n","\n","Epoch 00087: acc did not improve from 0.98320\n","Epoch 88/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7584 - acc: 0.9821 - val_loss: 7.8607 - val_acc: 0.9559\n","\n","Epoch 00088: acc did not improve from 0.98320\n","Epoch 89/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5922 - acc: 0.9825 - val_loss: 7.0303 - val_acc: 0.9601\n","\n","Epoch 00089: acc did not improve from 0.98320\n","Epoch 90/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5867 - acc: 0.9826 - val_loss: 7.0905 - val_acc: 0.9647\n","\n","Epoch 00090: acc did not improve from 0.98320\n","Epoch 91/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5671 - acc: 0.9827 - val_loss: 7.4021 - val_acc: 0.9613\n","\n","Epoch 00091: acc did not improve from 0.98320\n","Epoch 92/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5874 - acc: 0.9827 - val_loss: 7.2022 - val_acc: 0.9619\n","\n","Epoch 00092: acc did not improve from 0.98320\n","Epoch 93/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6889 - acc: 0.9824 - val_loss: 7.0305 - val_acc: 0.9645\n","\n","Epoch 00093: acc did not improve from 0.98320\n","Epoch 94/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6403 - acc: 0.9824 - val_loss: 7.1485 - val_acc: 0.9622\n","\n","Epoch 00094: acc did not improve from 0.98320\n","Epoch 95/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5777 - acc: 0.9827 - val_loss: 7.3294 - val_acc: 0.9626\n","\n","Epoch 00095: acc did not improve from 0.98320\n","Epoch 96/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6413 - acc: 0.9827 - val_loss: 7.4647 - val_acc: 0.9609\n","\n","Epoch 00096: acc did not improve from 0.98320\n","Epoch 97/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8514 - acc: 0.9817 - val_loss: 6.6204 - val_acc: 0.9629\n","\n","Epoch 00097: acc did not improve from 0.98320\n","Epoch 98/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5330 - acc: 0.9827 - val_loss: 7.0939 - val_acc: 0.9640\n","\n","Epoch 00098: acc did not improve from 0.98320\n","Epoch 99/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5465 - acc: 0.9829 - val_loss: 7.4214 - val_acc: 0.9615\n","\n","Epoch 00099: acc did not improve from 0.98320\n","Epoch 100/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5008 - acc: 0.9831 - val_loss: 7.5825 - val_acc: 0.9625\n","\n","Epoch 00100: acc did not improve from 0.98320\n","Epoch 101/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5921 - acc: 0.9825 - val_loss: 7.1933 - val_acc: 0.9596\n","\n","Epoch 00101: acc did not improve from 0.98320\n","Epoch 102/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5603 - acc: 0.9827 - val_loss: 7.0321 - val_acc: 0.9625\n","\n","Epoch 00102: acc did not improve from 0.98320\n","Epoch 103/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5477 - acc: 0.9827 - val_loss: 7.4322 - val_acc: 0.9627\n","\n","Epoch 00103: acc did not improve from 0.98320\n","Epoch 104/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6833 - acc: 0.9823 - val_loss: 7.5108 - val_acc: 0.9629\n","\n","Epoch 00104: acc did not improve from 0.98320\n","Epoch 105/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6233 - acc: 0.9824 - val_loss: 7.7953 - val_acc: 0.9583\n","\n","Epoch 00105: acc did not improve from 0.98320\n","Epoch 106/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9101 - acc: 0.9817 - val_loss: 6.9074 - val_acc: 0.9625\n","\n","Epoch 00106: acc did not improve from 0.98320\n","Epoch 107/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5071 - acc: 0.9827 - val_loss: 6.8570 - val_acc: 0.9636\n","\n","Epoch 00107: acc did not improve from 0.98320\n","Epoch 108/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4312 - acc: 0.9831 - val_loss: 6.4069 - val_acc: 0.9662\n","\n","Epoch 00108: acc did not improve from 0.98320\n","Epoch 109/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5541 - acc: 0.9826 - val_loss: 6.6087 - val_acc: 0.9639\n","\n","Epoch 00109: acc did not improve from 0.98320\n","Epoch 110/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7055 - acc: 0.9821 - val_loss: 6.8316 - val_acc: 0.9626\n","\n","Epoch 00110: acc did not improve from 0.98320\n","Epoch 111/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5389 - acc: 0.9827 - val_loss: 7.0610 - val_acc: 0.9616\n","\n","Epoch 00111: acc did not improve from 0.98320\n","Epoch 112/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5877 - acc: 0.9827 - val_loss: 7.1317 - val_acc: 0.9638\n","\n","Epoch 00112: acc did not improve from 0.98320\n","Epoch 113/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5093 - acc: 0.9829 - val_loss: 6.8235 - val_acc: 0.9611\n","\n","Epoch 00113: acc did not improve from 0.98320\n","Epoch 114/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4978 - acc: 0.9828 - val_loss: 6.9613 - val_acc: 0.9640\n","\n","Epoch 00114: acc did not improve from 0.98320\n","Epoch 115/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6254 - acc: 0.9823 - val_loss: 6.7807 - val_acc: 0.9649\n","\n","Epoch 00115: acc did not improve from 0.98320\n","Epoch 116/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8598 - acc: 0.9814 - val_loss: 7.0126 - val_acc: 0.9630\n","\n","Epoch 00116: acc did not improve from 0.98320\n","Epoch 117/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5315 - acc: 0.9828 - val_loss: 7.0034 - val_acc: 0.9611\n","\n","Epoch 00117: acc did not improve from 0.98320\n","Epoch 118/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5259 - acc: 0.9827 - val_loss: 6.7584 - val_acc: 0.9638\n","\n","Epoch 00118: acc did not improve from 0.98320\n","Epoch 119/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4712 - acc: 0.9828 - val_loss: 7.1338 - val_acc: 0.9615\n","\n","Epoch 00119: acc did not improve from 0.98320\n","Epoch 120/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4568 - acc: 0.9830 - val_loss: 6.9784 - val_acc: 0.9626\n","\n","Epoch 00120: acc did not improve from 0.98320\n","Epoch 121/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5170 - acc: 0.9827 - val_loss: 6.8050 - val_acc: 0.9645\n","\n","Epoch 00121: acc did not improve from 0.98320\n","Epoch 122/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5422 - acc: 0.9828 - val_loss: 7.0729 - val_acc: 0.9643\n","\n","Epoch 00122: acc did not improve from 0.98320\n","Epoch 123/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6368 - acc: 0.9825 - val_loss: 6.9556 - val_acc: 0.9624\n","\n","Epoch 00123: acc did not improve from 0.98320\n","Epoch 124/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7045 - acc: 0.9820 - val_loss: 7.7096 - val_acc: 0.9605\n","\n","Epoch 00124: acc did not improve from 0.98320\n","Epoch 125/500\n","769500/769500 [==============================] - 9s 11us/step - loss: 1.5192 - acc: 0.9828 - val_loss: 6.9945 - val_acc: 0.9635\n","\n","Epoch 00125: acc did not improve from 0.98320\n","Epoch 126/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6446 - acc: 0.9822 - val_loss: 7.4851 - val_acc: 0.9627\n","\n","Epoch 00126: acc did not improve from 0.98320\n","Epoch 127/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5946 - acc: 0.9825 - val_loss: 7.4479 - val_acc: 0.9638\n","\n","Epoch 00127: acc did not improve from 0.98320\n","Epoch 128/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4154 - acc: 0.9828 - val_loss: 6.9046 - val_acc: 0.9644\n","\n","Epoch 00128: acc did not improve from 0.98320\n","Epoch 129/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4443 - acc: 0.9826 - val_loss: 6.4799 - val_acc: 0.9638\n","\n","Epoch 00129: acc did not improve from 0.98320\n","Epoch 130/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7931 - acc: 0.9816 - val_loss: 6.5915 - val_acc: 0.9645\n","\n","Epoch 00130: acc did not improve from 0.98320\n","Epoch 131/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5181 - acc: 0.9826 - val_loss: 8.4040 - val_acc: 0.9549\n","\n","Epoch 00131: acc did not improve from 0.98320\n","Epoch 132/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5659 - acc: 0.9824 - val_loss: 6.8839 - val_acc: 0.9653\n","\n","Epoch 00132: acc did not improve from 0.98320\n","Epoch 133/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4375 - acc: 0.9830 - val_loss: 6.6895 - val_acc: 0.9654\n","\n","Epoch 00133: acc did not improve from 0.98320\n","Epoch 134/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4195 - acc: 0.9828 - val_loss: 7.2865 - val_acc: 0.9650\n","\n","Epoch 00134: acc did not improve from 0.98320\n","Epoch 135/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7363 - acc: 0.9820 - val_loss: 6.5862 - val_acc: 0.9651\n","\n","Epoch 00135: acc did not improve from 0.98320\n","Epoch 136/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5046 - acc: 0.9827 - val_loss: 6.8069 - val_acc: 0.9626\n","\n","Epoch 00136: acc did not improve from 0.98320\n","Epoch 137/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4065 - acc: 0.9829 - val_loss: 6.6061 - val_acc: 0.9635\n","\n","Epoch 00137: acc did not improve from 0.98320\n","Epoch 138/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7641 - acc: 0.9816 - val_loss: 6.5953 - val_acc: 0.9652\n","\n","Epoch 00138: acc did not improve from 0.98320\n","Epoch 139/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4268 - acc: 0.9827 - val_loss: 6.7186 - val_acc: 0.9641\n","\n","Epoch 00139: acc did not improve from 0.98320\n","Epoch 140/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4147 - acc: 0.9829 - val_loss: 6.7506 - val_acc: 0.9642\n","\n","Epoch 00140: acc did not improve from 0.98320\n","Epoch 141/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4663 - acc: 0.9829 - val_loss: 6.5977 - val_acc: 0.9647\n","\n","Epoch 00141: acc did not improve from 0.98320\n","Epoch 142/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4364 - acc: 0.9828 - val_loss: 6.4951 - val_acc: 0.9656\n","\n","Epoch 00142: acc did not improve from 0.98320\n","Epoch 143/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5894 - acc: 0.9823 - val_loss: 6.7668 - val_acc: 0.9646\n","\n","Epoch 00143: acc did not improve from 0.98320\n","Epoch 144/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7512 - acc: 0.9819 - val_loss: 6.5341 - val_acc: 0.9638\n","\n","Epoch 00144: acc did not improve from 0.98320\n","Epoch 145/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5140 - acc: 0.9826 - val_loss: 6.6178 - val_acc: 0.9641\n","\n","Epoch 00145: acc did not improve from 0.98320\n","Epoch 146/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4380 - acc: 0.9828 - val_loss: 6.4660 - val_acc: 0.9656\n","\n","Epoch 00146: acc did not improve from 0.98320\n","Epoch 147/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4813 - acc: 0.9825 - val_loss: 6.6840 - val_acc: 0.9667\n","\n","Epoch 00147: acc did not improve from 0.98320\n","Epoch 148/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3922 - acc: 0.9829 - val_loss: 7.0514 - val_acc: 0.9613\n","\n","Epoch 00148: acc did not improve from 0.98320\n","Epoch 149/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9795 - acc: 0.9810 - val_loss: 6.7249 - val_acc: 0.9639\n","\n","Epoch 00149: acc did not improve from 0.98320\n","Epoch 150/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4196 - acc: 0.9829 - val_loss: 6.2658 - val_acc: 0.9650\n","\n","Epoch 00150: acc did not improve from 0.98320\n","Epoch 151/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5299 - acc: 0.9823 - val_loss: 6.9921 - val_acc: 0.9635\n","\n","Epoch 00151: acc did not improve from 0.98320\n","Epoch 152/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5516 - acc: 0.9823 - val_loss: 6.4851 - val_acc: 0.9664\n","\n","Epoch 00152: acc did not improve from 0.98320\n","Epoch 153/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5140 - acc: 0.9824 - val_loss: 6.4363 - val_acc: 0.9670\n","\n","Epoch 00153: acc did not improve from 0.98320\n","Epoch 154/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5080 - acc: 0.9827 - val_loss: 7.4009 - val_acc: 0.9613\n","\n","Epoch 00154: acc did not improve from 0.98320\n","Epoch 155/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5272 - acc: 0.9825 - val_loss: 6.9003 - val_acc: 0.9660\n","\n","Epoch 00155: acc did not improve from 0.98320\n","Epoch 156/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6562 - acc: 0.9820 - val_loss: 6.6401 - val_acc: 0.9646\n","\n","Epoch 00156: acc did not improve from 0.98320\n","Epoch 157/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4321 - acc: 0.9829 - val_loss: 6.6276 - val_acc: 0.9675\n","\n","Epoch 00157: acc did not improve from 0.98320\n","Epoch 158/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3689 - acc: 0.9829 - val_loss: 6.3557 - val_acc: 0.9669\n","\n","Epoch 00158: acc did not improve from 0.98320\n","Epoch 159/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9059 - acc: 0.9813 - val_loss: 6.6085 - val_acc: 0.9654\n","\n","Epoch 00159: acc did not improve from 0.98320\n","Epoch 160/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4946 - acc: 0.9829 - val_loss: 6.4113 - val_acc: 0.9666\n","\n","Epoch 00160: acc did not improve from 0.98320\n","Epoch 161/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3558 - acc: 0.9830 - val_loss: 6.6824 - val_acc: 0.9648\n","\n","Epoch 00161: acc did not improve from 0.98320\n","Epoch 162/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5808 - acc: 0.9823 - val_loss: 6.5508 - val_acc: 0.9630\n","\n","Epoch 00162: acc did not improve from 0.98320\n","Epoch 163/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6440 - acc: 0.9818 - val_loss: 6.7877 - val_acc: 0.9637\n","\n","Epoch 00163: acc did not improve from 0.98320\n","Epoch 164/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5690 - acc: 0.9823 - val_loss: 6.7223 - val_acc: 0.9643\n","\n","Epoch 00164: acc did not improve from 0.98320\n","Epoch 165/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3773 - acc: 0.9828 - val_loss: 6.4515 - val_acc: 0.9672\n","\n","Epoch 00165: acc did not improve from 0.98320\n","Epoch 166/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4808 - acc: 0.9824 - val_loss: 6.5572 - val_acc: 0.9654\n","\n","Epoch 00166: acc did not improve from 0.98320\n","Epoch 167/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4403 - acc: 0.9827 - val_loss: 6.7487 - val_acc: 0.9641\n","\n","Epoch 00167: acc did not improve from 0.98320\n","Epoch 168/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4180 - acc: 0.9825 - val_loss: 7.5284 - val_acc: 0.9625\n","\n","Epoch 00168: acc did not improve from 0.98320\n","Epoch 169/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4053 - acc: 0.9828 - val_loss: 6.7807 - val_acc: 0.9646\n","\n","Epoch 00169: acc did not improve from 0.98320\n","Epoch 170/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3603 - acc: 0.9829 - val_loss: 6.4145 - val_acc: 0.9660\n","\n","Epoch 00170: acc did not improve from 0.98320\n","Epoch 171/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4743 - acc: 0.9825 - val_loss: 6.4806 - val_acc: 0.9673\n","\n","Epoch 00171: acc did not improve from 0.98320\n","Epoch 172/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6725 - acc: 0.9819 - val_loss: 6.7041 - val_acc: 0.9662\n","\n","Epoch 00172: acc did not improve from 0.98320\n","Epoch 173/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4731 - acc: 0.9826 - val_loss: 6.4577 - val_acc: 0.9646\n","\n","Epoch 00173: acc did not improve from 0.98320\n","Epoch 174/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4911 - acc: 0.9825 - val_loss: 6.3019 - val_acc: 0.9661\n","\n","Epoch 00174: acc did not improve from 0.98320\n","Epoch 175/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6874 - acc: 0.9817 - val_loss: 6.4693 - val_acc: 0.9653\n","\n","Epoch 00175: acc did not improve from 0.98320\n","Epoch 176/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4850 - acc: 0.9826 - val_loss: 6.3887 - val_acc: 0.9666\n","\n","Epoch 00176: acc did not improve from 0.98320\n","Epoch 177/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3462 - acc: 0.9828 - val_loss: 6.1495 - val_acc: 0.9677\n","\n","Epoch 00177: acc did not improve from 0.98320\n","Epoch 178/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4269 - acc: 0.9825 - val_loss: 6.2636 - val_acc: 0.9668\n","\n","Epoch 00178: acc did not improve from 0.98320\n","Epoch 179/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3669 - acc: 0.9827 - val_loss: 6.4918 - val_acc: 0.9669\n","\n","Epoch 00179: acc did not improve from 0.98320\n","Epoch 180/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4535 - acc: 0.9824 - val_loss: 6.7678 - val_acc: 0.9662\n","\n","Epoch 00180: acc did not improve from 0.98320\n","Epoch 181/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4377 - acc: 0.9825 - val_loss: 6.4630 - val_acc: 0.9674\n","\n","Epoch 00181: acc did not improve from 0.98320\n","Epoch 182/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4558 - acc: 0.9825 - val_loss: 6.5499 - val_acc: 0.9665\n","\n","Epoch 00182: acc did not improve from 0.98320\n","Epoch 183/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.2355 - acc: 0.9799 - val_loss: 6.4834 - val_acc: 0.9673\n","\n","Epoch 00183: acc did not improve from 0.98320\n","Epoch 184/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5858 - acc: 0.9823 - val_loss: 6.3449 - val_acc: 0.9661\n","\n","Epoch 00184: acc did not improve from 0.98320\n","Epoch 185/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3814 - acc: 0.9828 - val_loss: 6.9231 - val_acc: 0.9640\n","\n","Epoch 00185: acc did not improve from 0.98320\n","Epoch 186/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4774 - acc: 0.9826 - val_loss: 6.5662 - val_acc: 0.9673\n","\n","Epoch 00186: acc did not improve from 0.98320\n","Epoch 187/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5446 - acc: 0.9821 - val_loss: 6.0422 - val_acc: 0.9684\n","\n","Epoch 00187: acc did not improve from 0.98320\n","Epoch 188/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3403 - acc: 0.9828 - val_loss: 6.3916 - val_acc: 0.9649\n","\n","Epoch 00188: acc did not improve from 0.98320\n","Epoch 189/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4149 - acc: 0.9827 - val_loss: 6.3908 - val_acc: 0.9665\n","\n","Epoch 00189: acc did not improve from 0.98320\n","Epoch 190/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4439 - acc: 0.9825 - val_loss: 6.5695 - val_acc: 0.9660\n","\n","Epoch 00190: acc did not improve from 0.98320\n","Epoch 191/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4528 - acc: 0.9826 - val_loss: 6.4364 - val_acc: 0.9648\n","\n","Epoch 00191: acc did not improve from 0.98320\n","Epoch 192/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3955 - acc: 0.9825 - val_loss: 6.5572 - val_acc: 0.9671\n","\n","Epoch 00192: acc did not improve from 0.98320\n","Epoch 193/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7941 - acc: 0.9813 - val_loss: 6.2744 - val_acc: 0.9696\n","\n","Epoch 00193: acc did not improve from 0.98320\n","Epoch 194/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7212 - acc: 0.9818 - val_loss: 6.1751 - val_acc: 0.9685\n","\n","Epoch 00194: acc did not improve from 0.98320\n","Epoch 195/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4869 - acc: 0.9823 - val_loss: 6.2812 - val_acc: 0.9683\n","\n","Epoch 00195: acc did not improve from 0.98320\n","Epoch 196/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5036 - acc: 0.9824 - val_loss: 6.2155 - val_acc: 0.9687\n","\n","Epoch 00196: acc did not improve from 0.98320\n","Epoch 197/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3715 - acc: 0.9827 - val_loss: 6.3952 - val_acc: 0.9668\n","\n","Epoch 00197: acc did not improve from 0.98320\n","Epoch 198/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3289 - acc: 0.9828 - val_loss: 6.2430 - val_acc: 0.9667\n","\n","Epoch 00198: acc did not improve from 0.98320\n","Epoch 199/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3121 - acc: 0.9829 - val_loss: 6.3027 - val_acc: 0.9668\n","\n","Epoch 00199: acc did not improve from 0.98320\n","Epoch 200/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3875 - acc: 0.9827 - val_loss: 6.2526 - val_acc: 0.9664\n","\n","Epoch 00200: acc did not improve from 0.98320\n","Epoch 201/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5080 - acc: 0.9824 - val_loss: 6.6565 - val_acc: 0.9645\n","\n","Epoch 00201: acc did not improve from 0.98320\n","Epoch 202/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6313 - acc: 0.9822 - val_loss: 6.5969 - val_acc: 0.9659\n","\n","Epoch 00202: acc did not improve from 0.98320\n","Epoch 203/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3739 - acc: 0.9827 - val_loss: 6.7499 - val_acc: 0.9644\n","\n","Epoch 00203: acc did not improve from 0.98320\n","Epoch 204/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3830 - acc: 0.9828 - val_loss: 6.8116 - val_acc: 0.9649\n","\n","Epoch 00204: acc did not improve from 0.98320\n","Epoch 205/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7511 - acc: 0.9819 - val_loss: 6.1685 - val_acc: 0.9669\n","\n","Epoch 00205: acc did not improve from 0.98320\n","Epoch 206/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3347 - acc: 0.9830 - val_loss: 6.1308 - val_acc: 0.9671\n","\n","Epoch 00206: acc did not improve from 0.98320\n","Epoch 207/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4902 - acc: 0.9824 - val_loss: 5.9843 - val_acc: 0.9675\n","\n","Epoch 00207: acc did not improve from 0.98320\n","Epoch 208/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6282 - acc: 0.9820 - val_loss: 5.7581 - val_acc: 0.9683\n","\n","Epoch 00208: acc did not improve from 0.98320\n","Epoch 209/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3255 - acc: 0.9829 - val_loss: 6.0540 - val_acc: 0.9674\n","\n","Epoch 00209: acc did not improve from 0.98320\n","Epoch 210/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3131 - acc: 0.9830 - val_loss: 6.5889 - val_acc: 0.9668\n","\n","Epoch 00210: acc did not improve from 0.98320\n","Epoch 211/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3346 - acc: 0.9829 - val_loss: 6.3769 - val_acc: 0.9677\n","\n","Epoch 00211: acc did not improve from 0.98320\n","Epoch 212/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5941 - acc: 0.9823 - val_loss: 6.6253 - val_acc: 0.9671\n","\n","Epoch 00212: acc did not improve from 0.98320\n","Epoch 213/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7234 - acc: 0.9816 - val_loss: 6.1121 - val_acc: 0.9668\n","\n","Epoch 00213: acc did not improve from 0.98320\n","Epoch 214/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4159 - acc: 0.9828 - val_loss: 6.3042 - val_acc: 0.9659\n","\n","Epoch 00214: acc did not improve from 0.98320\n","Epoch 215/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2891 - acc: 0.9831 - val_loss: 6.2683 - val_acc: 0.9677\n","\n","Epoch 00215: acc did not improve from 0.98320\n","Epoch 216/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6629 - acc: 0.9820 - val_loss: 6.5443 - val_acc: 0.9643\n","\n","Epoch 00216: acc did not improve from 0.98320\n","Epoch 217/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5868 - acc: 0.9823 - val_loss: 6.3401 - val_acc: 0.9680\n","\n","Epoch 00217: acc did not improve from 0.98320\n","Epoch 218/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2808 - acc: 0.9832 - val_loss: 6.2127 - val_acc: 0.9666\n","\n","Epoch 00218: acc did not improve from 0.98320\n","Epoch 219/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3017 - acc: 0.9830 - val_loss: 6.1700 - val_acc: 0.9678\n","\n","Epoch 00219: acc did not improve from 0.98320\n","Epoch 220/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7942 - acc: 0.9815 - val_loss: 6.7545 - val_acc: 0.9664\n","\n","Epoch 00220: acc did not improve from 0.98320\n","Epoch 221/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4550 - acc: 0.9826 - val_loss: 6.2648 - val_acc: 0.9677\n","\n","Epoch 00221: acc did not improve from 0.98320\n","Epoch 222/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3253 - acc: 0.9830 - val_loss: 6.3482 - val_acc: 0.9660\n","\n","Epoch 00222: acc did not improve from 0.98320\n","Epoch 223/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3629 - acc: 0.9829 - val_loss: 6.0684 - val_acc: 0.9684\n","\n","Epoch 00223: acc did not improve from 0.98320\n","Epoch 224/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.9654 - acc: 0.9807 - val_loss: 6.1810 - val_acc: 0.9687\n","\n","Epoch 00224: acc did not improve from 0.98320\n","Epoch 225/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4266 - acc: 0.9825 - val_loss: 6.2595 - val_acc: 0.9678\n","\n","Epoch 00225: acc did not improve from 0.98320\n","Epoch 226/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3693 - acc: 0.9830 - val_loss: 6.7161 - val_acc: 0.9668\n","\n","Epoch 00226: acc did not improve from 0.98320\n","Epoch 227/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4550 - acc: 0.9825 - val_loss: 6.3087 - val_acc: 0.9676\n","\n","Epoch 00227: acc did not improve from 0.98320\n","Epoch 228/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3040 - acc: 0.9830 - val_loss: 6.3286 - val_acc: 0.9678\n","\n","Epoch 00228: acc did not improve from 0.98320\n","Epoch 229/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4867 - acc: 0.9822 - val_loss: 6.6933 - val_acc: 0.9645\n","\n","Epoch 00229: acc did not improve from 0.98320\n","Epoch 230/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7227 - acc: 0.9818 - val_loss: 5.8391 - val_acc: 0.9682\n","\n","Epoch 00230: acc did not improve from 0.98320\n","Epoch 231/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3642 - acc: 0.9828 - val_loss: 5.9556 - val_acc: 0.9696\n","\n","Epoch 00231: acc did not improve from 0.98320\n","Epoch 232/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3413 - acc: 0.9828 - val_loss: 6.3363 - val_acc: 0.9682\n","\n","Epoch 00232: acc did not improve from 0.98320\n","Epoch 233/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4391 - acc: 0.9825 - val_loss: 6.0328 - val_acc: 0.9672\n","\n","Epoch 00233: acc did not improve from 0.98320\n","Epoch 234/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3581 - acc: 0.9827 - val_loss: 6.7111 - val_acc: 0.9631\n","\n","Epoch 00234: acc did not improve from 0.98320\n","Epoch 235/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5781 - acc: 0.9822 - val_loss: 5.9808 - val_acc: 0.9684\n","\n","Epoch 00235: acc did not improve from 0.98320\n","Epoch 236/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4647 - acc: 0.9825 - val_loss: 6.2468 - val_acc: 0.9691\n","\n","Epoch 00236: acc did not improve from 0.98320\n","Epoch 237/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3615 - acc: 0.9827 - val_loss: 6.0048 - val_acc: 0.9683\n","\n","Epoch 00237: acc did not improve from 0.98320\n","Epoch 238/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3632 - acc: 0.9826 - val_loss: 6.3888 - val_acc: 0.9631\n","\n","Epoch 00238: acc did not improve from 0.98320\n","Epoch 239/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3600 - acc: 0.9827 - val_loss: 6.2467 - val_acc: 0.9692\n","\n","Epoch 00239: acc did not improve from 0.98320\n","Epoch 240/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5066 - acc: 0.9824 - val_loss: 6.0982 - val_acc: 0.9670\n","\n","Epoch 00240: acc did not improve from 0.98320\n","Epoch 241/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2631 - acc: 0.9830 - val_loss: 6.2139 - val_acc: 0.9689\n","\n","Epoch 00241: acc did not improve from 0.98320\n","Epoch 242/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3778 - acc: 0.9827 - val_loss: 6.3066 - val_acc: 0.9682\n","\n","Epoch 00242: acc did not improve from 0.98320\n","Epoch 243/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1320 - acc: 0.9799 - val_loss: 6.7538 - val_acc: 0.9626\n","\n","Epoch 00243: acc did not improve from 0.98320\n","Epoch 244/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5194 - acc: 0.9824 - val_loss: 6.0145 - val_acc: 0.9687\n","\n","Epoch 00244: acc did not improve from 0.98320\n","Epoch 245/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2932 - acc: 0.9829 - val_loss: 6.5245 - val_acc: 0.9665\n","\n","Epoch 00245: acc did not improve from 0.98320\n","Epoch 246/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3145 - acc: 0.9829 - val_loss: 6.2980 - val_acc: 0.9679\n","\n","Epoch 00246: acc did not improve from 0.98320\n","Epoch 247/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2531 - acc: 0.9832 - val_loss: 6.1708 - val_acc: 0.9672\n","\n","Epoch 00247: acc improved from 0.98320 to 0.98322, saving model to /content/drive/My Drive/Colab Notebooks/Dacon/competition_!/247_0.98322.hdf5\n","Epoch 248/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.1682 - acc: 0.9799 - val_loss: 6.2510 - val_acc: 0.9676\n","\n","Epoch 00248: acc did not improve from 0.98322\n","Epoch 249/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7291 - acc: 0.9815 - val_loss: 6.1302 - val_acc: 0.9668\n","\n","Epoch 00249: acc did not improve from 0.98322\n","Epoch 250/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4935 - acc: 0.9823 - val_loss: 6.1147 - val_acc: 0.9657\n","\n","Epoch 00250: acc did not improve from 0.98322\n","Epoch 251/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3697 - acc: 0.9827 - val_loss: 5.9573 - val_acc: 0.9682\n","\n","Epoch 00251: acc did not improve from 0.98322\n","Epoch 252/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3661 - acc: 0.9827 - val_loss: 6.2347 - val_acc: 0.9686\n","\n","Epoch 00252: acc did not improve from 0.98322\n","Epoch 253/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3774 - acc: 0.9826 - val_loss: 5.7932 - val_acc: 0.9686\n","\n","Epoch 00253: acc did not improve from 0.98322\n","Epoch 254/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5015 - acc: 0.9823 - val_loss: 6.1198 - val_acc: 0.9673\n","\n","Epoch 00254: acc did not improve from 0.98322\n","Epoch 255/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4033 - acc: 0.9824 - val_loss: 6.3895 - val_acc: 0.9685\n","\n","Epoch 00255: acc did not improve from 0.98322\n","Epoch 256/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3332 - acc: 0.9827 - val_loss: 6.0881 - val_acc: 0.9668\n","\n","Epoch 00256: acc did not improve from 0.98322\n","Epoch 257/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2840 - acc: 0.9831 - val_loss: 5.8682 - val_acc: 0.9695\n","\n","Epoch 00257: acc did not improve from 0.98322\n","Epoch 258/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2843 - acc: 0.9831 - val_loss: 5.9667 - val_acc: 0.9683\n","\n","Epoch 00258: acc did not improve from 0.98322\n","Epoch 259/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6092 - acc: 0.9819 - val_loss: 5.9252 - val_acc: 0.9688\n","\n","Epoch 00259: acc did not improve from 0.98322\n","Epoch 260/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4585 - acc: 0.9824 - val_loss: 5.8821 - val_acc: 0.9676\n","\n","Epoch 00260: acc did not improve from 0.98322\n","Epoch 261/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3038 - acc: 0.9830 - val_loss: 6.1575 - val_acc: 0.9677\n","\n","Epoch 00261: acc did not improve from 0.98322\n","Epoch 262/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4342 - acc: 0.9824 - val_loss: 6.5396 - val_acc: 0.9654\n","\n","Epoch 00262: acc did not improve from 0.98322\n","Epoch 263/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5755 - acc: 0.9819 - val_loss: 5.8925 - val_acc: 0.9696\n","\n","Epoch 00263: acc did not improve from 0.98322\n","Epoch 264/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5886 - acc: 0.9818 - val_loss: 6.0170 - val_acc: 0.9699\n","\n","Epoch 00264: acc did not improve from 0.98322\n","Epoch 265/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5539 - acc: 0.9820 - val_loss: 5.7637 - val_acc: 0.9715\n","\n","Epoch 00265: acc did not improve from 0.98322\n","Epoch 266/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3465 - acc: 0.9828 - val_loss: 5.6307 - val_acc: 0.9706\n","\n","Epoch 00266: acc did not improve from 0.98322\n","Epoch 267/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3144 - acc: 0.9830 - val_loss: 5.6463 - val_acc: 0.9696\n","\n","Epoch 00267: acc did not improve from 0.98322\n","Epoch 268/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3840 - acc: 0.9827 - val_loss: 5.9160 - val_acc: 0.9700\n","\n","Epoch 00268: acc did not improve from 0.98322\n","Epoch 269/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4308 - acc: 0.9825 - val_loss: 5.7708 - val_acc: 0.9701\n","\n","Epoch 00269: acc did not improve from 0.98322\n","Epoch 270/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.6671 - acc: 0.9816 - val_loss: 6.4236 - val_acc: 0.9661\n","\n","Epoch 00270: acc did not improve from 0.98322\n","Epoch 271/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.8403 - acc: 0.9812 - val_loss: 7.6278 - val_acc: 0.9575\n","\n","Epoch 00271: acc did not improve from 0.98322\n","Epoch 272/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5482 - acc: 0.9821 - val_loss: 6.2970 - val_acc: 0.9671\n","\n","Epoch 00272: acc did not improve from 0.98322\n","Epoch 273/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4900 - acc: 0.9824 - val_loss: 6.0545 - val_acc: 0.9699\n","\n","Epoch 00273: acc did not improve from 0.98322\n","Epoch 274/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2527 - acc: 0.9830 - val_loss: 5.7599 - val_acc: 0.9695\n","\n","Epoch 00274: acc did not improve from 0.98322\n","Epoch 275/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2250 - acc: 0.9832 - val_loss: 5.9241 - val_acc: 0.9704\n","\n","Epoch 00275: acc did not improve from 0.98322\n","Epoch 276/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4034 - acc: 0.9826 - val_loss: 5.9609 - val_acc: 0.9696\n","\n","Epoch 00276: acc did not improve from 0.98322\n","Epoch 277/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5418 - acc: 0.9822 - val_loss: 5.7056 - val_acc: 0.9699\n","\n","Epoch 00277: acc did not improve from 0.98322\n","Epoch 278/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4146 - acc: 0.9826 - val_loss: 5.5940 - val_acc: 0.9710\n","\n","Epoch 00278: acc did not improve from 0.98322\n","Epoch 279/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3147 - acc: 0.9828 - val_loss: 6.0478 - val_acc: 0.9687\n","\n","Epoch 00279: acc did not improve from 0.98322\n","Epoch 280/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2905 - acc: 0.9827 - val_loss: 6.1266 - val_acc: 0.9676\n","\n","Epoch 00280: acc did not improve from 0.98322\n","Epoch 281/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 2.0346 - acc: 0.9802 - val_loss: 6.3722 - val_acc: 0.9655\n","\n","Epoch 00281: acc did not improve from 0.98322\n","Epoch 282/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3647 - acc: 0.9829 - val_loss: 6.1073 - val_acc: 0.9676\n","\n","Epoch 00282: acc did not improve from 0.98322\n","Epoch 283/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2446 - acc: 0.9829 - val_loss: 5.6139 - val_acc: 0.9693\n","\n","Epoch 00283: acc did not improve from 0.98322\n","Epoch 284/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3041 - acc: 0.9828 - val_loss: 6.2069 - val_acc: 0.9679\n","\n","Epoch 00284: acc did not improve from 0.98322\n","Epoch 285/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3078 - acc: 0.9828 - val_loss: 5.9835 - val_acc: 0.9678\n","\n","Epoch 00285: acc did not improve from 0.98322\n","Epoch 286/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2759 - acc: 0.9829 - val_loss: 5.9800 - val_acc: 0.9660\n","\n","Epoch 00286: acc did not improve from 0.98322\n","Epoch 287/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2899 - acc: 0.9830 - val_loss: 5.7428 - val_acc: 0.9707\n","\n","Epoch 00287: acc did not improve from 0.98322\n","Epoch 288/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.4539 - acc: 0.9824 - val_loss: 5.9032 - val_acc: 0.9681\n","\n","Epoch 00288: acc did not improve from 0.98322\n","Epoch 289/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.5015 - acc: 0.9822 - val_loss: 5.8595 - val_acc: 0.9680\n","\n","Epoch 00289: acc did not improve from 0.98322\n","Epoch 290/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3471 - acc: 0.9827 - val_loss: 6.1955 - val_acc: 0.9688\n","\n","Epoch 00290: acc did not improve from 0.98322\n","Epoch 291/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2432 - acc: 0.9829 - val_loss: 5.7814 - val_acc: 0.9674\n","\n","Epoch 00291: acc did not improve from 0.98322\n","Epoch 292/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2348 - acc: 0.9830 - val_loss: 6.2632 - val_acc: 0.9670\n","\n","Epoch 00292: acc did not improve from 0.98322\n","Epoch 293/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3138 - acc: 0.9827 - val_loss: 8.3774 - val_acc: 0.9554\n","\n","Epoch 00293: acc did not improve from 0.98322\n","Epoch 294/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7500 - acc: 0.9812 - val_loss: 5.8329 - val_acc: 0.9677\n","\n","Epoch 00294: acc did not improve from 0.98322\n","Epoch 295/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2876 - acc: 0.9829 - val_loss: 5.6482 - val_acc: 0.9710\n","\n","Epoch 00295: acc did not improve from 0.98322\n","Epoch 296/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.7130 - acc: 0.9813 - val_loss: 5.7136 - val_acc: 0.9706\n","\n","Epoch 00296: acc did not improve from 0.98322\n","Epoch 297/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2967 - acc: 0.9827 - val_loss: 6.0409 - val_acc: 0.9687\n","\n","Epoch 00297: acc did not improve from 0.98322\n","Epoch 298/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.2683 - acc: 0.9829 - val_loss: 5.6750 - val_acc: 0.9716\n","\n","Epoch 00298: acc did not improve from 0.98322\n","Epoch 299/500\n","769500/769500 [==============================] - 9s 12us/step - loss: 1.3088 - acc: 0.9827 - val_loss: 6.1168 - val_acc: 0.9679\n","\n","Epoch 00299: acc did not improve from 0.98322\n","Epoch 300/500\n","376000/769500 [=============>................] - ETA: 4s - loss: 1.4323 - acc: 0.9822"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-107-6cf284274d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_train_o2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"UpoolWWPr8yk"},"source":["from keras.models import load_model\n","\n","model = load_model(work_dir + '247_0.98322.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kR3eFiEdHYY4","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1580324784604,"user_tz":-540,"elapsed":90634,"user":{"displayName":"‍이지현[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"08616836268514229893"}},"outputId":"ebdca805-0561-4fe1-b914-f244f0f3eafa"},"source":["# loss \n","\n","loss = model.evaluate(fea_train , tar_train_o2, batch_size = 32)\n","print('loss: ', str(loss))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["810000/810000 [==============================] - 90s 111us/step\n","loss:  [1.5746846950224889, 0.9813308641975309]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xhRbAYYzwgz7"},"source":["pred_test_2 = model.predict(fea_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1m07A4_JHUL2"},"source":["submission = pd.read_csv(work_dir + 'sample_submission.csv', index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukhNSbgvJ0we"},"source":["submission[['layer_1', 'layer_3']] = pred_test_1\n","submission[['layer_2', 'layer_4']] = pred_test_2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDrfvd9tVvCS"},"source":["submission.to_csv(work_dir +'submission_7.csv')"],"execution_count":null,"outputs":[]}]}